[{"title":"I/O管理（操作系统笔记10）","date":"2023-01-25T01:12:47.000Z","url":"/2023/01/25/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0-10/","tags":[["操作系统","/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"]],"categories":[["操作系统笔记","/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/"]],"content":"本章开始会讲解I/O设备管理的相关知识，这也是操作系统的最后一章。 第十章 I/O管理接下来我们进入操作系统的最后一个功能，I/O管理。 10.1 I/O设备“I/O”就是“输入/输出” I/O设备就是可以将数据输入到计算机，或者可以接收计算机输出数据的外部服务，属于计算机中的硬件部件 UNIX系统将外部设备抽象为一种特殊的文件，用户可以使用与文件操作系统相同的方式将外部设备进行操作 I/O设备可以按以下方式进行分类： 按使用特性分类： 人机交互类外部设备：数据传输速度慢（比如：鼠标、键盘、打印机等），用于人机交互 存储设备：数据传输速度快（比如：移动硬盘、光盘等），用于数据存储 网络通信设备：数据传输通信设备（比如：调制解调器），用于网络通信 按传输速率分类： 低速设备：鼠标、键盘等，传输速率为每秒几个到几百字节 中速设备：如激光打印机等，传输速率为每秒数千至上万个字节 高速设备：如磁盘等，传输速率为每秒数千字节至千兆字节的设备 按信息交换单位分类： 块设备：传输速率较高，可寻址，即对它可随机的读/写任一块，数据传输的基本单位是“块”，如磁盘等 字符设备：传输效率较慢，不可寻址，在输入/输出时长采用中断驱动方式，数据传输的基本单位是字符，如键盘鼠标等。 10.2 I/O设备的组成I/O设备分为机械部件和电子部件 机械部件：主要用来执行具体I/O操作。如我们看得见鼠标、键盘的按钮，显示器的LED屏 电子部件：通常是一块插入主板扩充槽的印刷电路板 (1)电子部件中的I/O控制器的功能CPU无法直接控制I/O设备的机械部件，因此I/O设备还要有一个电子部件作为CPU和I/O设备机械部件之间的“中介”，用于实现CPU对设备的控制。这个电子部件就是I/O控制器，又称设备控制器。CPU可控制I/O控制器，又由I/O控制器来控制设备的机械部件。 注： 一个I/O控制器可能对应多个设备 数据寄存器，控制寄存器，状态寄存器可能有多个，且都要有相应的的值才能方便CPU操作。 设置地址的方法有两种： 内存映像I/O 计算机会让这些寄存器占用内存地址的一部分，这称为内存映射I/O 寄存器独立编址 计算机则采用I/O专用地址，这称为寄存器独立编址 两种方式的比较 10.3 操作系统控制I/O设备方式(1)程序直接控制方式 (2)中断驱动方式 (3)DMA方式虽然中断驱动方式解决了程序直接控制方式的问题，但是每一次只能读/写一个字，导致CPU频繁切换，耗费了很多时间。于是人们又发明了DMA方式。 使用一个DMA控制器，让I/O控制器直接与内存进行交互，可以一次性传送多个数据块 (4)通道控制方式通道控制方式是为了解决DMA方式连续存储的问题。 通道是一个硬件，他是一个特化CPU，只能用于执行一系列通道指令。CPU将需要处理的I/O请求相关数据提供给通道，之后执行其他进程，至于I/O处理就交给通道完成了。 最后对四种方式进行总结： 10.4 I/O软件的层次结构I/O软件由上至下分别是：用户层软件，设备独立性软件，设备驱动程序，中断处理程序，硬件 (1)用户层软件用户层软件实现了与用户交互的接口，用户可直接使用该层提供的、与I/O操作相关的库函数对设备进行操作 用户层软件将用户请求翻译成格式化的I/O请求，并通过“系统调用”请求操作系统内核的服务 也就是对系统调用的一种封装，同时负责把这种封装翻译成系统调用。 (2)设备独立性软件（设备无关性软件）主要实现以下功能： 向上层提供统一的调用接口 设备的保护，与文件保护类似 差错处理 设备的分配与回收 数据缓冲区管理 建立逻辑设备名到物理设备名的映射关系，根据设备类型选择调用相应的驱动程序 为了实现逻辑设备名和物理设备名的映射关系，并找到该设备对应的设备驱动程序我们需要建立逻辑设备表。 (3)设备驱动程序不同设备的内部硬件特性不同，规定不同，所以不同的设备需要不同的方法去操纵或访问设备，于是就有了设备驱动程序 (4)中断处理程序 总结： 10.5 I/O核心子系统(1)假脱机技术（SPOOLing技术）要知道什么是假脱机技术首先要知道什么是脱机技术。 由于CPU与I/O的速度不匹配，人们想出的第一个发子就是将I/O与主机控制脱离开，比如批处理系统先用外围控制机将纸带转化为磁带， 在脱机技术的基础上人们发明了更好的假脱机技术 “输入进程”模拟脱机输入时的外围控制机，“输出进程”模拟脱机输出时外围控制机 输入缓冲区：在输入进程的控制下，输入缓冲区用于暂存从输入设备输入的数据，之后再转存到输入井中 输出缓冲区：在输出进程的控制下，输出缓冲区用于暂存从输出井送来的数据，之后再传送到输出设备上 注意：两个缓冲区均在内存中 假脱机技术可以完成独占式设备转换为共享设备。 需要了解的是：假脱机技术一般在用户层软件 (2)I/O调度I/O调度主要是I/O设备的分配与回收 再分配时我们需要考虑以下几个因素： 固有属性：独占设备、共享设备、虚拟设备 分配算法：先来先服务、优先级高者优先、短任务优先等 安全性： 安全分配方式：为进程分配一个设备后就将进程阻塞，本次I/O完成后才将进程唤醒。 优点：破坏了“请求和保持”条件，不会死锁 缺点：对于一个进程来说，CPU和I/O设备只能串行工作 不安全分配方式：进程发出I/O请求后，系统为其分配/O设备，进程可继续执行，之后还可以发出新的I/O请求。只有某个I/O请求得不到满足时才将进程阻塞。 优点：进程的计算任务和I/O任务可以并行处理，时进程迅速推进 缺点：有可能发生死锁 有以下两类分配方式 静态分配：进程运行前为其分配全部所需资源，运行结束后归还资源 动态分配：进程运行过程中动态申请设备资源 设备分配中会用到相应的数据结构： 设备控制表： 控制器控制表： 通道控制表： 系统设备表： 设备分配步骤： 根据进程请求的物理设备名查找SDT(注：物理设备名是进程请求分配设备时提供的参数) 根据SDT找到DCT,若设备忙碌则将进程PCB挂到设备等待队列中，不忙碌则将设备分配给进程。 根据DCT找到COCT,若控制器忙碌则将进程PCB挂到控制器等待队列中，不忙碌则将控制器分配给进程。 根据COCT找到CHCT,若通道忙碌则将进程PCB挂到通道等待队列中，不忙碌则将通道分配给进程。 这种方法有些缺点： 用户编程时必须使用“物理设备名”，底层细节对用户不透明，不方便编程 若换了一个物理设备，则程序无法运行 若进程请求的物理设备正在忙碌，则即使系统中还有同类型的设备，进程也必须阻塞等待 改进方法：建立逻辑设备名与物理设备名的映射机制，用户编程时只需提供逻辑设备名 (3)缓冲区管理缓冲区是一个存储区域，可以由专门的硬件寄存器组成，也可利用内存作为缓冲区。 使用硬件作为缓冲区的成本较高，容量也较小，一般仅用在对速度要求非常高的场合（如存储器管理中所用的联想寄存器，由于对页表的访问频率极高，因此使用速度很快的联想寄存器来存放页表项的副本) 一般情况下，更多的是利用内存作为缓冲区，“设备独立性软件”的缓冲区管理就是要组织管理好这些缓冲区 缓冲区主要由以下几个作用： 缓和CPU与I/O设备之间速度不匹配的矛盾 减少对CPU的中断频率，放宽对CPU中断响应时间的限制 解决数据粒度不匹配的问题 提高CPU与I/O设备之间的并行性 单缓冲区: 双缓冲:系统在内存中提供两个缓冲区，当第一个缓冲区充满后，输入设备可以向二号缓冲区装入。而操作系统可以将议号缓冲区中数据移出并进行处理。 单缓冲与双缓冲的区别： 循环缓冲区： 缓冲池： "},{"title":"磁盘组织与管理（操作系统笔记9）","date":"2023-01-24T12:33:47.000Z","url":"/2023/01/24/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0-9/","tags":[["操作系统","/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"]],"categories":[["操作系统笔记","/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/"]],"content":"本章开始会讲解磁盘也就是外存的硬件系统的相关知识 第九章 磁盘组织与管理9.1 磁盘的组成 9.2 磁盘调度算法(1)一次磁盘读/写操作需要的时间寻找时间（寻道时间）$T_s$：在读/写数据前，将磁头移动到指定刺刀所花时间 启动磁头臂需要时间的。假设耗时为s 移动磁头也是需要时间的。假设磁头匀速移动，没跨越一个磁道耗时为m，总共需要跨越n条磁道 T_s=s+m*n延迟时间$T_R$：通过旋转磁盘，使磁头定位到目标扇区所需要的时间。 磁盘转速为r（转/秒） 平均延迟时间： T_R=\\frac{1}{2r}传输时间$T_t$：从磁盘读出或向磁盘写入数据所经历的时间 磁盘转速为r 此次读/写的字节数为b 每个磁道上的字节数为N T_t=\\frac{b}{rN}总的平均存取时间 T_a=T_s+\\frac{1}{2r}+\\frac{b}{rN}延迟时间和存储时间与磁盘转速相关，且为线性相关，这是磁盘的固有属性，所以一般来说无法优化。但是操作系统的磁盘调度算法会直接影响寻道时间。 (2)先来先服务（FCFS） (3)最短寻找时间优点算法（SSTF） (4)扫描算法（SCAN） (5)LOOK算法 (6)循环扫描算法 (7)C-LOOK算法 9.3 减少延迟时间的方法磁头读入一个扇区数据后需要一小段时间处理，如果逻辑上相邻的扇区在物理上也相邻，则读入几个连续的逻辑扇区，可能需要很长的“延迟时间” (1)交替编号若采用交替编号的策略，即让逻辑上相邻的扇区在物理上有一定的间隔，可以使读取连续的逻辑扇区所需要的延迟时间更小。 磁盘地址结构的设计： 所以采用（柱面号，盘面号，扇区号）的地址结构可以减少磁头移动消耗的时间。 (2)错位命名假设我们现在的0号盘面与1号盘面相同的盘面位置相同处扇区标号相同，现在我们需要访问玩(000，00,111)之后访问(000,01,000)。 如果读取完磁盘块(000，00,111)之后，需要短暂的时间处理，而盘面又在不停地转动，因此当(000,01,000)第一次划过1号盘面的磁头下方时，并不能读取数据，只能再等该扇区再次划过磁头。 这显然是不划算的。 如果我们将0号盘面与1号盘面相同盘面位置对应不同盘面号形成错位命名就可以加快磁盘的读取速度 9.4 磁盘管理(1)磁盘初始化 物理格式化：划分扇区 磁盘分区：分成C盘，D盘之类的 逻辑格式化：建立文件系统（建立根目录文件、建立用于存储空间管理的数据结构） (2)磁盘引导块计算机启动时需要运行初始化程序，来完成初始化。ROM（只读存储器）中存放很小的自举装入程序，完整的自举程序存放在初始块（引导块）中。 (3)坏块的管理简单的磁盘：逻辑格式化时将坏块标记出来 复杂的磁盘：磁盘控制器维护一个坏块链，并管理备用扇区"},{"title":"文件系统（操作系统笔记8）","date":"2023-01-22T02:43:47.000Z","url":"/2023/01/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0-8/","tags":[["操作系统","/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"]],"categories":[["操作系统笔记","/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/"]],"content":"本章开始会讲解操作系统功能的第三个部分文件管理，详细了解操作系统是如何管理文件的。 第八章 文件系统8.1 文件系统概述文件：一组有意义的信息集合 文件的属性： 文件名：由创建文件的用户决定文件名，主要是为了方便用户找到文件，同一目录下不允许有重名文件 标识符：一个系统内的各文件表示唯一，对用户来说毫无可读性，因此标识符知识操作系统用于区分各个文件的一种内部结构 类型：指明文件的类型 位置：文件存放的路径（用户使用）、在外存的位置（供操作系统使用） 大小：指明文件大小 保护信息：对文件进行保护的访问控制信息 其他信息 文件的内部用一些逻辑结构组织起来 文件的外部则通过目录结构组织起来 操作系统需要向上提供相应的系统调用供用户控制文件，包括：create（创建），delete（删除），open（打开），close（关闭），read（读取），write（写入）等系统调用 文件在外存中也会通过相应的物理结构存储 操作系统也会提供相应的管理方式 最后操作系统需要提供文件的共享和保护功能，接下来我们会对这些功能逐一介绍 8.2 文件的逻辑结构(1)无结构文件无结构文件指的是文件内部的数据就是一些列二进制流或字符流组成。又称“流式文件”。 最典型的就是Windows里面的.txt文件 (2)有结构文件有结构文件： 由一组相似的记录组成，又称“记录式文件”。每条记录又若干各数据项组成。 根据各条记录的长度是否相等，又可分为定长记录和可变长记录。 定长记录： 不定长记录： (3)有结构文件的逻辑结构顺序文件： 顺序文件：文件中的记录一个接一个地顺序排列（逻辑上），记录可以是定长的或可变长的。各个记录在物理上可以顺序存储或链式存储。 链式存储无法实现随机存取，所以一般不考虑。 顺序存储中，可变长记录无法实现随机存取，每次只能从第一个记录开始依次往后查找。而定长记录可实现随机存取。 顺序存储的缺点：增加/删除一个记录比较困难。 索引文件： 索引文件：建立一张索引表，每个记录对应一个表项，各记录不用保持顺序，方便增加/删除记录 索引表：索引表本身就是定长记录的顺序文件一个索引表项就是一条定长记录，因此索引文件可支持随机存取 若索引表按关键字排序，则可支持快速检索。 解决了顺序文件不方便增/删记录的问题，同时让不定长记录的文件实现了随机存取。但素引表可能占用很多空间 索引顺序文件： 索引顺序文件：将记录分组，每组对应一个索引表项 检查方式：检查记录时先顺序查索引表，找到分组，再顺序朝朝分组 当记录过多时，可建立多级索引表 8.3 文件的目录结构(1)文件控制块为了能对一个文件进行正确的存取，必须为文件设置用于描述和控制文件的数据结构，称为进程控制块（FCB）。 一个文件对应一个FCB,一个FCB就是一个目录项，多个FCB组成文件目录。 在FCB中通常应该包含3类信息： 基本信息类： 文件名：用于标志一个文件的符号名 文件物理位置：指文件在外存中的存储位置 文件逻辑结构：知识文件时六文件还是记录式文件 文件的物理结构：指示文件在外存的存储位置 存取控制信息类：存取控制信息类 使用信息类：文件建立时间，修改时间，是否被锁等信息 通过文件控制块我们需要对目录完成以下操作： 搜索、创建文件、删除文件、显示文件、修改文件 (2)目录结构(2.1)单级目录结构 (2.2)两级页表目录 (2.3)树形目录 (2.4)无环图目录 (3)索引节点索引节点是对FCB的优化，将除了文件名之外的所有信息都放到索引节点中，每个文件对应一个索引节点 目录象中只包含文件名，索引节点指针，因此每个目录象的长度大幅缩小 由于目录项长度减小，因此每个磁盘块可以存放更多个目录项，检索文件时磁盘I/O的次数少了很多 8.4 文件的物理结构文件块：类似于内存分页，磁盘中的存储单元也会被分为一个个“块/磁盘块/物理块”。内存与磁盘之间的数据都是以“块”为单位进行的。级每次读入一块，或每次写出一块。 (1)连续分配方式：连续分配方式要求每个文件在磁盘上占有一组连续的块。 地址映射：$物理块号=起始块号+逻辑块号$，$物理地址=物理块号+块内地址$ 文件目录中记录存放的起始块号和长度。 由于可以直接算出逻辑块号的物理块号，因此连续分配支持顺序访问和随机访问。 优点： 支持顺序访问和随机访问 由于读取某个磁盘块时，需要移动磁头。访问的连个磁盘块相隔越远，移动磁头所需时间就越长。连续分配的文件在顺序读/写速度最快。 缺点： 物理上采用连续分配的文件不方便拓展 存储空间利用率低，会产生难以利用的磁盘碎片，可以用紧凑来解决，但是需要耗费很大的时间代价 (2)链接分配方式：采用离散分配的方式，可以为文件分散的磁盘块。分为隐式链接和显式链接两种。 (2.1)隐式链接方式： 目录中记录了文件存放的起始块号和结束块号，也可以增加一个字段来表示文件的长度。 除了文件的最后一个磁盘块之外，每个磁盘块中都会保存指向下一个盘块的指针，这些指针对用户是透明的。 地址转换：从目录项中找到起始块号（即0号块），将0号逻辑块读入内存，由此知道1号逻辑块存放的物理块号，于是读入1号逻辑块，再找到2号逻辑块的存放位置…以此类推。因此，读入i号逻辑块，总共需要i+1次磁盘I/O 优点： 方便拓展文件 不会有碎片问题 外存利用率高 缺点： 只支持顺序访问，不支持随机访问，查找效率低。 指向下一个盘块的指针也需要耗费少量的存储空间 (2.2)显式链接方式： 把用于连接文件各物理块的指针显示地存放在一张表中。即文件分配表（FAT），一个磁盘仅需设置一张，开机时将FAT读入内存，并常驻内存。 目录中只需要保存起始块号 地址转移：从目录项中找到起始块号，若&gt;0，则查询内存中的文件分配表FAT,往后找到i号逻辑块对应的物理块号。逻辑块号转换成物理块号的过程不需要读磁盘操作。 优点: 方便拓展文件 不会有碎片问题 外存利用率高 支持随机访问 地址转换时不需要访问磁盘,因此文件地访问效率更高 缺点: 文件分配表需要占用一定地存储空间 (3)索引分配方式：索引分配允许文件离散地分配在各个磁盘块中，系统会为每个文件建立一张索引表，索引表中记录了文件的各个逻辑块对应的物理块（索引表的功能类似于内存管理中的页表一一建立逻辑页面到物理页之间的映射关系)。索引表存放的磁盘块称为索引块。文件数据存放的磁盘块称为数据块。 地址转换：目录中记录索引块位置，将索引表从外存读入内存，并查找索引表即可得到i号逻辑块在外存中的存放位置。 优点： 支持随机访问 文件拓展也很容易实现 索引表需要占用一定的存储空间 缺点： 索引表需占用一定的存储空间 访问数据块前需要限度如索引块 索引表连接方案： 如果索引表太大，一个索引块装不下，那么可以将多个索引块连接起来存放。 缺点：若文件很大，索引表很长，就需要将很多各索引块连接起来。想要找到i号索引块，必须先一次读入0~i-1号索引块，这就导致磁盘I/O次数过多，查找效率低下。 多层索引：建立多层索引（原理类似于多级页表）。使第一层索引块指向第二层的索引块。还可根据文件大小的要求再建立第三层、第四层索引块。 混合索引：多种索引分配方式的结合。例如，一个文件的顶级索引表中，既包含直接地址索引（直接指向数据块)，又包含一级间接索引（指向单层索引表）、还包含两级间接索引（指向两层索引表） 8.5 文件存储区空间的管理在为文件分配盘块时，因此必须知道磁盘上那些盘块是可用于分配的。在位文件分配盘块是，除了需要文件分配表歪，系统还应为可分配存储空间设置相应的数据结构，即设置一个磁盘分配表，用于记住可提供分配的存储空间情况。此外还应提供对盘块进行分配和回收的手段。 (1)存储空间的换份与初始化 (2)空闲表法方式：空闲表中记录每个连续空去的起始盘块号，盘块数 分配磁盘块：与内存管理中的动态分区分配很类似，为一个文件分配连续的存储空间。同样可采用首次适应、最佳适应、最坏适应等算法来决定要为文件分配哪个区间。 回收磁盘块：与内存管理中的动态分区分配很类似，当回收某个存储区时需要有四种情况 回收区的前后都没有相邻空闲区 回收区的前后都是空闲区 回收区前面是空闲区 回收区后面是空闲区。 总之，回收时需要注意表项的合并问题。 (3)空闲链表法可把链表分为两种形式： (3.1)空闲盘块链 (3.2)空闲盘区链 (3.3)位示图法 分配方法：若文件需要K个块 顺序扫描位示图，找到K个相邻或不相邻的“0” 根据字号、位号算出对应的盘块号，将相应盘块分配给文件 将相应位设置为“1” 回收方法： 根据回收的盘块号计算出对应的字号、位号 将相应二进制位设为“0” (4)成组链接法空闲表法、空闲链表法不适用于大型文件系统，因为空闲表或空闲链表可能过大。UNIX系统中采用了成组链接法对磁盘空闲块进行管理。 文件卷的目录区中专门用一个磁盘块作为“超级块”，当系统启动时需要将超级块读入内存。并且要保证内存与外存中的“超级块”数据一致。 分配方法： Eg：需要100个空闲块 检查第一个分组的块数是否足够。100=100，是足够的。 分配第一个分组中的100个空闲块。但是由于300号块内存放了再下一组的信息，因此300号块的数据需要复制到超级块中 回收方法： Eg：假设每个分组最多为100个空闲块 此时第一个分组已有99个块，还要再回收一块。需要将超级块中的数据增加上这个块 此时第一个分组已有100个块，还要再回收一块。需要将超级块中的数据复制到新回收的块中，并修改超级块的内容，让新回收的块成为第一个分组。 8.6 文件操作原理 8.7 文件共享文件共享主要分为两种：基于索引节点的共享方式也被称为硬链接，基于符号量的共享方式被称为软链接。 (1)基于索引节点（硬链接） (2)基于符号链的共享方式 其实就是快捷方式 8.8 文件保护 8.9 文件系统层次结构 用户接口：文件系统需要向上层的用户提供一些简单易用的功能接口。这层就是用于处理用户发出的系统调用请求(Read、Write、Open、Close等系统调用) 文件目录系统：用户是通过文件路径来访问文件的，因此这一层需要根据用户给出的文件路径找到相应的FCB或索引结点。所有和目录、目录项相关的管理工作都在本层完成，如：管理活跃的文件目录表、管理打开文件表等 存取控制模块：为了保证文件数据的安全，还需要验证用户是否有访问权限。这一层主要完成了文件保护相关功能。 逻辑文件系统与文件信息缓冲区：用户指明想要访问文件记录号，这一层需要将记录号转换为对应的逻辑地址 物理文件系统：这一层需要把上一层提供的文件逻辑地址转换为实际的物理地址 辅助分配模块：负责文件存储空间的管理，即负责分配和回收存储空间 设备管理模块：直接与硬件交互，负责和硬件直接相关的一些管理工作。如：分配设备、分配设备缓冲区、磁盘调度、启动设备、释放设备等 "},{"title":"虚拟内存（操作系统笔记7）","date":"2023-01-20T06:20:47.000Z","url":"/2023/01/20/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0-7/","tags":[["操作系统","/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"]],"categories":[["操作系统笔记","/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/"]],"content":"本章会介绍虚拟内存技术是如何做到内存的扩充的，这一章只是相对来说较为抽象，但是虚拟内存已经广泛的运用于各种操作系统。 第七章 虚拟内存在上一章内存管理中我们稍微介绍了内存扩充技术，包括对换与覆盖进行扩充，而这一章我们将介绍内存扩充最重要的技术，那就是虚拟内存技术，学会了这章你就能明白为什么你的电脑内存只有16G，却能运行30G的游戏了。 7.1 传统存储管理方式的特征传统的存储管理方式有如下两点特征： 一次性：作业必须一次性全部装入内存后才能开始运行。 缺点： 作业很大时，不能全部装入内存，导致大作业无法运行 当大量作业要求运行时，由于内存无法容纳所有作业，因此只有少量作业能运行，导致多道程序并发度降低 驻留性：一旦作业被装入内存，就会一直驻留在内存中，直至作业运行结束。 缺点： 内存中会驻留大量的、暂时用不到的数据，浪费宝贵的内存资源 在结合我们之前介绍的局部性原理，传统存储管理方式已经很难满足这些需求了，也无法应用局部性原理优化，于是衍生出了内存扩充技术。 7.2 虚拟内存的定义与特征 虚拟内存主要有以下三个特征： 多次性：无需再作业云高兴是一次性全部装入内存，而是允许多次调入内存。 对换性：再作业运行时无需一直常驻内存，而是允许作业在运行过程中，将作业换出、换入。 虚拟性：从逻辑上扩充了内存的容量，时用户看到的内存容量，远大于实际的容量。 实现虚拟内存技术主要有以下三种方式： 请求分页存储管理 请求分段存储管理 请求段页式存储管理 虽然形式有所不同，但是他们都要实现以下两点： 访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存（请求调页功能） 内存空间不够时，将内存中赞时用不到的信息换出到外存（页面置换功能） 7.3 请求分页管理方式(1)请求分页存储管理与基本分页存储管理的区别请求分页存储管理与基本分页存储管理的主要区别： 在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需信息从外存调入内存，然后继续执行程序。 若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。 请求分页存储管理的页表与基本分页存储管理的页表的主要区别： ![]() #### (2)缺页中断机构 1. 找到页表项后检查页面是否已在内存，若没在内存，产生缺页中断 2. 缺页中断处理中，需要将目标页面调入内存，有必要时还要换出页面 3. 缺页中断属于内中断，属于内中断中的“故障”，即可能被系统修复的异常 4. 一条指令在执行过程中可能产生多次缺页中断 ![]() #### (3)地址变换机构 ![]() ### 7.4 页面置换算法 #### (1)最佳置换算法 规则：优先淘汰最长时间内不会被访问的页面。 优点：保证最低的缺页率 缺点：操作系统只有个在进程执行的过程中才知道接下来会访问到那个页面。因此最佳置换算法是无法实现的。 (2)先进先出置换算法（FIFO）规则：每次选择淘汰的页面是最早进入内存的页面 实现方法：把调入内存的页面根据调入的先后顺序排成一个队列，需要换出页面时选择对头页面即可。队列的最大长度取决于系统未进程分配了多少个内存块。 优点：实现简单 缺点： 该算法与进程实际运行时的规律不适应，算法性能差。 会产生Belady异常：党委进程分配的物理块数增大时，缺页次数不减反增的异常现象（只有FIFO算法会产生） (3)最近最久未使用置换算法（LRU）规则：每次淘汰的页面时最近最久未使用的页面 实现方法：赋予每个页面对应的页表项中，用访问字段记录该页面自上次被访问依赖所经历的时间t。当需要淘汰一个页面时，选择现有页面中t值最大的，即最近最久未使用页面。 优点：性能号 缺点：需要专门的硬件支持，实现困难，开销大 (4)时钟置换算法（CLOCK）规则：将最近未使用的算法进行置换，所以也称为最近未用算法 实现方法：为每个页面是指一个访问位，再将内存中的页面都通过链接指针链接成一个循化队列。当某页被访问时，其访问位置位为1，当需要淘汰一个页面时，只需检查页的访问位，如果是0，就选择换出；如果是1，则将它置为0，暂不换出，继续检查下一个页面，若第一轮扫描中所有页面都是1，则将这些页面的访问位一次置为0后，进行第二轮扫描。（最多会经过两轮扫描） 优点：实现简单，算法开销小 缺点：未考虑页面被修改导致的I/O (5)改造型时钟置换算法 算法开销小，且性能也不错，就是理解起来有点麻烦。 7.5 页面分配策略(1)驻留集请求分页存储管理中各进程分配的物理块的集合被称为驻留集。 在采用了虚拟存储技术的系统中，驻留集大小一般小于进程的总大小。 若驻留集太小，会导致缺页平凡，系统要花大量的时间来处理缺页，实际用于进程推进的时间很小； 驻留集太大，又会导致多道陈旭并发度下降，资源利用率降低。所以应该选择一个合适的驻留集大小。 那么怎样分配驻留集就是我们这章需要讨论的问题。 (2)页面分配置换策略固定分配： 操作系统为每个进程分配一组固定数目的物理块，在进程运行期间不再改变。即，驻留集大小不变。 可变分配： 先为每个进程分配一定数目的物理块，在进程运行期间，可根据情况做适当的增加或减少。即驻留集大小可变 局部置换：发生缺页时只能选进程自己的物理块进行置换 全局置换：可以将操作系统保留的空闲物理块分配给缺页进程，也可以将别的进程持有的物理块置换到外存，在分配给缺页进程 7.6 调入页面的时机 7.7 调页位置 7.7 抖动现象刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又换出内存，这种频繁的页面调度行为称为抖动（颠簸）产生抖动的主要原因时进程频繁访问的页面数目高于可用的物理快数（分配给进程的物理块不够） 7.8 工作集"},{"title":"内存管理（操作系统笔记6）","date":"2023-01-12T08:13:47.000Z","url":"/2023/01/12/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0-6/","tags":[["操作系统","/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"]],"categories":[["操作系统笔记","/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/"]],"content":"本章将进入内存管理的学习，包括内存分配回收等，内容不少于之前的进程同步和互斥，且容易考大题 第六章 内存管理6.1 多层结构的存储器计算机在执行指令的时候，几乎每条指令都会设计对存储器的访问，因此要求计算机对存储器的访问速度能跟的上处理机的运行速度，并且同时我们还要追求存储器容量大，价格低。 这三个条件目前来说是不可能同时满足的，于是现代计算机无一例外的采用了多层结构的存储器。 存储结构至少具有三层：最高层为CPU寄存器，中间层为主存储器，最底层为辅助存储器。层次越高，读取速度越快，存储容量越小，价格越低。 而主存储器就是我们平常说的内存，在程序执行的时我饿们要如何定位各个程序的数据放在哪个位置呢？ 为此我们将存储器的空间分为一个一个的存储单元。存储单元的大小与计算机的编址方式有关，如果计算机是按字节编址的 ，则每个存储单元的大小为1字节，也就是8个二进制位，弱国计算机是按字编址的，则每个存储单元大小为一个字。每个字的大小也与计算机有关。 6.2 进程运行的基本原理从源代码变成正在执行的进程主要分三步：编译，链接，装入。 编译：由编译程序将用户源代码编译成若个个目标模块（把高级语言翻译成机器语言） 链接：由链接陈旭将编译后新城的一组目标模块，以及所需库函数链接在一起，形成一个完成的装入模块 装入：由装入程序将装入模块装入内存运行 (1)地址绑定和内存保护程序中的地址在不同的步骤有着不同的表示方法。在源程序中的地址通常用符号表示，比如定义一个整形变量count，那么这个count就是源程序中的地址表示方法。编译器通常将这些符号地址绑定在可重定位的地址或相对地址上。链接程序或装入程序再将这些相对地址绑定到绝对地址。每次绑定都是从一个地址空间到另一个地址空间的映射。CPU申城的地址通常称为逻辑地址或相对地址。而内存单元看到的地址通常称为物理地址（绝对地址）。 内存分配前，需要保护操作系统不受用户进程的影响，同时保护用户进程不受其他用户进程的影响。通过釆用重定位寄存器和界地址寄存器来实现这种保护。重定位寄存器含最小的物理地址值，界地址寄存器含逻辑地址值。每个逻辑地址值必须小于界地址寄存器；内存管理机构动态地将逻辑地址与界地址寄存器进行比较，如果未发生地址越界，则加上重定位寄存器的值后映射成物理地址，再送交内存单元。每一个逻辑地址都需要与这两个寄存器进行核对，以保证操作系统和其他用户程序及数据不被该进程的运行所影响。 (2)程序的链接程序的链接方式分为三种： 静态链接：在程序运行之前先将个目标模块及他们所需的库函数连接成一个完整的可执行文件，之后不再拆开 装入时动态链接：将个目标模块装如内存时，边装入边链接的链接方式 运行时动态链接：在程序执行中需要改目标模块时，才对它进行链接，其优点是加快装入过程，可节省大量内存空间 (3)程序的装入程序装入内存中的时候必须要将相对地址修改成绝对地址，否则就不知道所对应的地址具体存在内存的哪个位置了。 装入也有三种方式（将逻辑地址转化成物理地址）： 绝对装入：在编译时，如果知道程序将放到内存中的哪个位置，编译程序将产生绝对地址的目标代码，装入程序按照装入模块中的地址，将程序和数据装入内存。 这种方式仅使用与单道程序环境，也就是直接使用绝对地址编程。 静态重定位： 动态重定位： 6.3 内存管理介绍了这么多内存的东西，那么操作系统作为系统资源的管理者，在内存管理中需要做什么呢？事实上操作系统主要完成以下的内容： 内存空间的分配和回收。 内存空间的扩展（实现虚拟内存） 覆盖技术 交换技术 虚拟内存技术 负责程序的逻辑地址与物理地址的转换 绝对装入 可重定位装入 动态运行时装入 内存保护 设置一对上下限寄存器，存放进程的上、下限地址。进程的指令要访问某个地址时，CPU检查是否越界。 采用重定位寄存器（基址寄存器）和界地址寄存器（限长寄存器）进行越界检查。重定位寄存器存放的时进程的起始物理地址。界地址寄存器中存放的是进程的最大逻辑地址。 对于地址转换和内存保护我们都已经在之前进行了详细的阐述，而分配和回收是我们后面的重头戏，所以我们先放在这里，现在对于内存空间的扩展中的覆盖技术和交换技术进行讲解，而虚拟内存技术也是会在后面重点介绍。 (1)覆盖技术 (2)对换技术 暂时被换出外存等待的进程就会变成挂起态 6.4 内部碎片与外部碎片 内部碎片：分配给某些进程的内存区域中，没有用上的部分久交内存碎片 外部碎片：是指内存中的某些空闲分区由于太小而难以利用 6.5 内存的分配和回收（1）内存分配管理方式分为：连续分配管理方式，非连续分配管理方式 (1)连续分配管理连续分配：只为用户进程分配的必须是一个连续的内存空间。 (1.1)单一连续分配内存被分为系统区和用户区。系统区通常为与内存的低地址部分，用于存放操作系统相关数据，用户区用于存放用户进程相关数据。 内存中只能有个一道用户程序，用户程序独占整个用户区空间。 优点：实现简单，无外部碎片，可采用覆盖技术扩充内存，不一定需要采取内存保护 缺点：只能用于单用户，单任务的操作系统，有内部碎片，存储器利用率低 (1.2)固定分区分配将单一连续分配的用户区划分为若干个固定大小的分区，在每个分区中只装入一道作业。 固定分区分配也分为两种：分区大小相等，分区大小不等 分区大小相等：缺乏灵活性，但是哼适用于用一台计算机控制多个相同对象的场合 分区大小不等：增加了灵活性，可以满足不同大小的进程需求 (1.3)动态分区分配动态分区分配又称为可变分区分配。这种分配方式不会预先划分内存分区，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程地需要。因此系统分区的大小和数目是可变的。 这种方式会衍生出三个问题： 系统要用怎样的数据结构记录内存的使用情况？ 当多个空闲分区都能满足要求时应该选则哪个分区进行分配？（动态分区分配算法后面会详细介绍） 如何进行分区的分配和回收操作 对存储结构进行修改 动态分区分配在没有内部碎片，但是又外部碎片。 如果内存中空闲空间的总和本来可以满足某进程的有球单由于进程需要的是一整块连续的内存空间，因此这些“碎片”不能满足进程的需求。但是我们可以通过紧凑技术来解决外部碎片。 6.6 动态分区分配算法 首次适应算法 算法思想：每次都从低地址开始查找，找到第一个能满足大小的空闲分区。 实现方式：空闲分区以地址递增的次序排列。每次分配内存时顺序查找空闲分区表（空闲分区链），找到大小能满足要求的第一个空闲分区。 优点：综合看性能最好，算法开销小,回收分区后一般不许要对空闲分区队列重新排序。 最佳适应算法 算法思想：由于动态分区分配是一种连续分配方式，为各进程分配的控件必须是连续的一整片区域，因此为了保证当“大进程”到来时有连续的大片控件，可以尽可能多地留下大片的空闲区域，有限使用更下的空闲区。 实现方式：空闲分区按容量递增次序排序。每次分配内存时顺序查找空闲分区表（空闲分区链），找到大小能满足要求的第一个空闲分区。 优点：会有更多的打分去呗保留下来，更能满足大进程需求 缺点：会产生很多太小的、难以利用的碎片，算法开销大，回收分区后可能需要对空闲分区队列重新排序 最坏适应算法 算法思想：为了解决最佳适应算法的问题（留下太多难以利用的小碎片），在每次分配时有限使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用。 实现方式：空闲分区按容量递减次序链接。每次分配内存时顺序查找空闲分区表（空闲分区链），找到大小能满足要求的第一个空闲分区。 优点：可以减少难以利用的小碎片 缺点：大分区容易被用完，不利于大进程，算法开销大 邻近适应算法 算法思想：首次适应算法每次都要从链头开始查找的。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些这些分区，增加查找开销。如果每次都从上次查找位置开始检索，就能解决上述问题。 实现方式：空闲分区一地址递增的顺序排，每次分配内存时从上次查找结束的位置开始查找空闲分区表（空闲分区链），找到大小能满足要求的第一个空闲分区。 优点：不用每次都从低地址的小分区开始检索。算法开销小 缺点：回时高地址的大分区也被用完 6.5 内存的分配和回收（2）连续分配强调为用户进程分配的必须是一个连续的内存空间。 非连续分配强调为用户进程分配的可以时一些分散的内存空间。 在正式介绍非连续分配管理方式前，我们先看看连续分配管理方式有什么问题。 首先是固定分区分配：缺乏灵活性，会产生大量的内部碎片，内存的利用率低。 然后是动态分区分配：会产生很多外部碎片，虽然可以用“紧凑”技术来处理，但是“紧凑”的时间待见很高。 (2)非连续分配管理方式(2.1)分页存储管理借用固定分区分配的方式，将内存分为一个个相等的小分区，但与固定分区分配不同的是并不将一个进程全部放进一个个小分区，而是将进程按照分区大小把进程拆分成一个个小部分，离散的分配在内存中。 而我们将内存空间分为一个个大小相等的分区，每个分区就是一个“页框”（“页帧”、“内存块”、“”物理块），每个页框有一个标号，即“页框号”（“页帧号”，“内存块号”，“物理块号”），页框号从0开始。 将用户进程的地址空间也分为与页框大小相等的一个个区域，称为“页”（“页面”）。每个页面也有个编号，即“页号”，页号也从0开始。 注：进程的最后一个页面可能没有一个页框呢么大，因此，页框不能太大，否则可能产生过大的内部碎片 操作系统以页框为单位为各个进程分配内存空间，进程的每个页面分别放入一个页框中。也就是说，进程的页面与内存的页框有一一对应的关系。 各个页面不必连续存放，页不必按先后顺序来，可以放到不想零的各个页框中。 分页虽然能够解决一个进程要很大一块连续内存不好分配的麻烦，但是操作系统就不知到如何将逻辑地址转换成物理地址了。 页号的计算方式： 页号=\\frac{逻辑地址}{页面长度}页内偏移量的计算方式： 页内偏移量=逻辑地址\\%页面长度物理地址的计算方式： 物理地址=页面起始地址+页内偏移量上面的方法是我们平时做题的时候的方法，但是计算机是使用二进制的，他反而更加方便 方法我们知道了，但是还有个问题我们没解决，就是我们要知道该页号对应页面在内存中的起始地址，为此我们引入一个新概念：页表 为了能知道进程的每个页面在内存中存放的位置，操作系统要为每个进程建立一张页表 一个进程对应一张页表 进程的每一页对应一个页表项 每个页表项由“页号”和“块号”组成 页表记录进程页面和实际存放的内存块之间的对应关系 每个页表项的长度是相同的，页号是“隐含”的 为什么每个页表项的长度相同，页号是隐含的呢？ 了解了分页机制，我们再来具体到逻辑地址与物理地址转换上，看一下大概是一个怎样的流程来完成这项工作的。 我们把完成这项工作的结构称为基本地址变换结构 通常会在系统中设置一个页表寄存器（PTR），存放页表在内存中的起始地址F和页表长度M,进程为执行时，页表的起始地址和页表长度存放在进程控制块（PCB）中，当进程被调度时，操作系统内核会把他们放到页表寄存器中。然后经历以下几个步骤。 更具逻辑地址算出页号、页内偏移量 页号的合法性检查（与页表长度对比） 若页号合法，在根据页表起始地址，页号找到对应页表项（第一次访问内存） 根据页表象中记录的内存块号、页内偏移量得到最终的物理地址 访问物理内存对应的内存单元（第二次访问内存） 注：实际应用中，通常使一个页恰好能放入整数个页表项 (2.1.1)引入快表的分页存储管理我们了解了基本地址变换结构的分页存储管理，发现对于寻找到逻辑地址对应的物理地址至少要访问两次内存，虽然内存的访问速度很快，但是对于CPU来说还是远远不够的，为了访问页表而专门访问一次内存太花时间了。但是页表很大不可能放入更高速的存储设备中。按理来说这个问题无解，但是我们引入一个新原理。 局部性原理： 时间局部性：如果执行流程序中的某条指令，那么不久后这条指令很有可能被再次执行；如果某个数据被访问过，不就后该数据很可能再次被访问。（程序中存在大量的循环） 空间局部性：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元很有可能被访问。（因为很多数据在内存中都是连续存放） 由于局部性原理，可能连续很多次查到的都是同一个页表项。为此我们可以将页表的部分可能会被访问到的项放入更快速的存储器中。我们将其称为快表。 快表：又称联想寄存器（TLB），是一种访问速度比内存快很多的高速缓冲存储器，用来存放到前访问的若干页表项，以加速地址变换的过程。于此对应，内存中的页表常称为慢表。 引入快表后地址表换结构就会有所改变： CPU给出逻辑地址，断初页号、页内偏移量，将页号与快表中的页号进行对比 若找到匹配的页号，说明要访问的页表项在快表中有副本，则直接从快表中找到内存块号，与页内偏移量凭借形成物理地址，最后，访问该物理地址对应的内存单元。（只需访问一次内存） 如果没有找到匹配的页号，则需要访问内存中的页表，找到对应的页表项（要判定是否越界），最后与页内偏移量组成物理地址。在访问内存相应物理单元。（访问两次内存） 基本地址变换与快表地址变换的比较 (2.1.2)二级页表当我们使用分页存储时我们并没有考虑页表有多大，为了能够快速查找到需要的页表项，所以页表一定是连续存储的，如果我们的页表太大，我们就需要一块很大的连续空间用于存储页表。 而我们当初引入页表的目的就是为了防止进程需要很大一块连续的内存，如果不想办法解决这个问题，那么就违背了我们引入分页的初衷，所以我们引入了二级页表。 对页表再次进行分页这样我们就可以把一个长长的页表分散的存储在内存中，并为页表创建一张页表，称为页目录表，或称为外层页表，或称为顶层页表。 那二级页表地址转换是怎样的呢？ 按照地址结构讲逻辑地址拆分为三部分 从PCB中读出页目录表起始地址，再根据一级页号查页目录表，找到下一级页表在内存中的存放位置 根据二级页号查表，找到最终像访问的内存块号 结合页内偏移量得到物理地址 首先需要明确的是不一定只有二级页表，也有可能采用多级页表。若没有快表，每多一级页表，对内存的访问次数就要多1。一级页表仅需要两次，二级需要三次，以此类推。 重点：很多人可能会对页表怀有不切实际的幻想，比如页表分级越多，页表对内存的占用就会越少，其实不然，将页表分级只是为了将页表打碎了放入内存，但是它该占多少的位置还是占多少位置，而且因为引入另外一张页表，会导致内存占用更大。 (2.1.3)反置页表正如上面所说多级页表虽然能将大页表打散，但是对于内存的占用并不会减少，甚至会变得更大，这对于内存来说是十分的不划算的，这主要是因为我们之前的页表是用逻辑页号来查找的，只要进程的内存需要的够大，那么页表就会越大。且每多一个进程就得重新给他划分一块区域装页表。 如果我们换一种思路，我们页表记录的不再是虚拟地址→物理地址的映射，而是物理地址→逻辑地址的映射，这样无论进程需要多大的内存，有多少的内存，页表大小都只与物理地址有关。 那要如何将虚拟地址和物理地址对应上呢？ 如果将反置页表做成之前的页表一样线性的，那么依次检索起来将会非常耗费性能，所以一般会使用哈希算法来进行存储，不过哈希算法可能会出现“地址冲突”的问题，必须妥善解决这个问题。 并且如果所需要的地址不在内存中，将直接无法找到这个内存（其他页表可以使用虚拟内存技术），所以为了找到不在内存中的地址还需要为每个进程建立一个外部页表，这个页表和创痛页表一样，当所访问的页表不在内存中，就需要通过外部页表找到他。 (2.2)分段存储管理方式前面的无论是分页还是前面的连续分配管理都是为了提供内存的利用率。而引入分短短存储管理方式的主要目的是满足用户在编程和使用上的多方面要求，有些要求是其他集中存储管理方式所难以满足的。因此，分段存储管理方式已成为当今所有存储管理方式的基础。 那么什么是分段呢？ 分段的逻辑地址结构与分页相近，始有段号（段名）和段内地址（段内偏移量）所组成。 段号的位数决定了每个进程最多可以分几个段 段内地址位数决定了每个段的最大长度。 程序分多个段，各断离散地装入内存，为了保证程序能正常运行，就必须想办法将逻辑地址和物理地址对应上，为此需为每个进程建立一张段映射表，简称“段表”。 由于和分页不一样，每一段的长度都不同，所以相对于页表我们需要多存储一个段的长度，用于判断是否会产生越界。 但是各个段表项长度是相同的。所以段表项应包含段长，基址。 分段具体的地址变换流程： 由逻辑地址得到段号，段内地址 段号与段表寄存器中的长度进行比较，判断是否越界（重要） 由段表起始地址、段号找到对应段表项 根据段表中记录的段长，检查段内地址是否越界 由段表中的“基址+段内地址”得到物理地址 访问目标单元 (2.3)分页和分段的比较： 对于信息的共享和保护为什么分段好实现而分页却不好实现呢？ (2.3)段页式存储管理方式先分析一下分页式管理和分段式管理的优缺点 如果能将这两种方式结合一下就能达到相当不错的效果 怎样结合呢？ 将地址空间按照程序自身的逻辑关系划分成若干段，在将各段分为大小相等的页面 将内存空间划分为与页面大小相等的一个个内存块，系统以块为单位为进程分配内存 逻辑地址结构变为：段号，页号，页内偏移量 当然既然分了段也分了页，那么一个进程都会对应一个段表，每个段又会对应一个页表。 段页式管理的地址转换过程又是怎样呢？ 由逻辑地址得到段号，页号，页内偏移量 段号与段表寄存器中的段长度进行比较，检查是否越界 由段表始址、段号找到相应段表项 更具段表中记录的页表长度，检查页号是否越界 由段表中的页表地址、页号得到查询页表，找到相应页表项 由页表存放的内存块号、页内偏移量得到最终的物理地址 访问目标单元 当然也可以引入快表机制，加快寻址速度 若未引入快表需要三次访问内存： 查段表 查页表 访问目标单元 引入快表后，以段号和页号未关键字查询快表，即可直接找到最终的目标页面存放为置。引入快表后仅需一次访问内存。 "},{"title":"进程同步与互斥（操作系统笔记5）","date":"2023-01-04T07:47:47.000Z","url":"/2023/01/04/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0-5/","tags":[["操作系统","/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"]],"categories":[["操作系统笔记","/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/"]],"content":"本篇笔记将介绍一下进程的同步与互斥，由于进程的异步性会产生非常多的包括死锁等问题。本章主要讲述如何处理或解决这些问题。 第五章 进程同步与互斥5.1 进程同步与互斥 进程同步 进程同步也被称为直接制约关系。 假设有两个进程他们有明确的先后执行的关系，但是因为操作系统的异步性，导致后执行的先执行造成程序错误就会得不偿失了，所以我们需要对后执行的进程加以制约确保他后执行。 例如，让系统计算1 + 2x3，假设系统产生两个进程: 一个是加法进程，一个是乘法进程。要让计算结果是正确的，一定要让加法进程发生在乘法进程之后,但实际上操作系统具有异步性,若不加以制约，加法进程发生在乘法进程之前是绝对有可能的，因此要制定一定的机制去约束加法进程，让它在乘法进程完成之后才发生。 进程互斥 进程互斥是一种间接制约的关系。 首先我们先介绍一个概念，临界资源 我们把一个时间段内只允许一个进程使用的资源称为临界资源。（特别是物理设备，如摄像头、打印机） 对临界资源的访问一定要互斥的执行，还是拿打印机举个例子，你不能打印三国演义打着打着打西游记了吧，这下就真成四大名著合订本了。 对临界资源的互斥访问的代码可以分以下四块： 进入区：负责检查是否可以使用资源，如果可以则要设置有进程正在访问的标志 临界区：访问临界资源的那段代码 退出区：负责解除有进程正在访问的标志 剩余区：做其他处理 未来实现对临界资源的互斥访问，保证系统整体性能，需遵循四条规则： 空闲让进：临界区空闲时，可以允许一个请求进入临界区 忙则等待：当已有进程进入临界区是，其他试图进入临界区的进程必须等待 有限等待：对亲求访问的进程，应保证能在有限时间内进入临界区 让权等待：当进程不能进入临界区是，应立即释放处理机，防止忙等待（占着茅坑不拉屎） 5.2 软件实现互斥的方法这块我自己讲不清楚，就把别人文章中的截图粘贴过来了，图片均来自 单标志法： 双标志先检查： 双标志后检查： Peterson算法（重要） 这个算法看似解决了前面算法的所有问题，但是同时也出现了新问题，我们会发现当进程进不去临界区时，一直在while循环里面空耗CPU，这就违反了让权等待的原则，虽然相较于其他三个算法已经是最好的了，但依然不够好，接下来我们通过硬件来实现。 5.3 硬件实现互斥的方法这块同上，图片均来自： 开关中断 Test-and-Set指令实现硬件版单标志法，但是由于硬件可以直接在资源上面动刀子，这可比软件带劲。 假设lock现在为false，代表临界资源A空闲，那么我就可以访问这个资源，同时将lock=true，提醒别的进程，这个临界资源A我正在使用，让他们等等 假设lock为true，代表临界资源正在有人使用，所以我必须等待，并且将lock=true，并不影响什么，所以没关系，只是为了让lock为false时可以上锁，将上锁与检查在一个TSL指令完成。 Swap指令和TestAndSet指令有一曲同工之妙，甚至连问题都是一样的 我们发现这几个算法虽然各有千秋，但是都有些的问题： 在双标志法中，进入区的“检查”，“上锁”操作无法一起呵成，从而导致同时进临界区或同时进不去的问题。、 所有的解决发难都无法实现“让权等待” 这个时候我们隆重介绍我们的重量级选手：信号量机制 5.4 信号量机制信号量机制的重点就是wait、signal原语。常称为P、V操作。 接下来看看信号量机制的流程： 整型信号量（不重要） 整型信号量还是不行，依然解决不了让权等待，再来看看记录型信号量 记录型信号量 5.5 信号量机制实现进程互斥和同步我们了解了信号量机制的原理，那我们就大概明白了如何实现进程的互斥。 这也是做题和解决问题最基础的方法。 实现进程互斥 确定临界区 设置互斥信号量，设置处值为1 临界区之前对信号量执行P操作 临界区之后为信号量执行V操作 实现进程同步 首先找出“一前一后”的关系 设置同步信号量，初始值为0 在“后操作”之后执行V操作 在“前操作”之后执行P操作 实现前驱关系 画出前驱图，讲每一对前驱关系看成一个同步问题 为每一对前驱关系设置同步信号量 在每个“后操作”之前执行P操作 在每个“前操作”之后执行V操作 前驱关系可能不太好理解，前驱关系其实就是一个有向图 5.6 进程同步互斥经典问题(1)生产者-消费者问题 系统中有一组生产者进程和一组消费者进程，生产者进程每次生产一个产品放入缓冲区，消费者进程每次从缓冲区中取出一个产品并使用。(注: 这里的“产品”理解为某种数据) 生产者、消费者共享一个初始为空、大小为n的缓冲区。 只有缓冲区没满时，生产者才能把产品放入缓冲区，否则必须等待。 只有缓冲区不空时，消费者才能从中取出产品，否则必须等待。 缓冲区是临界资源，各进程必须互斥地访问。 分析：生产者和消费者对缓冲区互斥访问是互斥关系，同时生产者和消费者又有前后关系，所以他们也是同步关系，而且还是两个同步关系。分别是有空才能放，不空才能取。那么我们就需要三个信号量。 重点：实现互斥的P操作一定要在实现同步的P操作之后，否则会造成死锁。V操作则不受限制。 理由：假设我们缓冲区满了，这个时候生产者决定写入进程，于是先将通过P操作进入临界区，结果在临界区发现缓冲区满了，于是进行阻塞，切换到消费者，因为生产者并没有通过V操作释放缓冲区，所以消费者也没法进入缓冲区进行消费，此时两个进程均处于阻塞，均需要对方的资源，导致死锁。 (1.1)多生产者-多消费者问题 问题分析：首先可以确定的是对于盘子这个缓冲区的访问一定是互斥的，只有父亲放苹果儿子才能吃，所以这是一对同步关系，只有母亲放橘子女儿才能吃，这又是一对同步关系，只有盘子为空时，父亲或者母亲才能放水果，这又是一对同步关系，与是我们可以定义四个信号量。 其实本题是个特殊案例，因为缓冲区只有1，所以即使没有mutex实现互斥，apple，orange，plate之中也只会有一个是1，从而进入临界区，一旦缓冲区变成2，那么就必须要mutex实现互斥了，否则可能会造成覆盖。 (2)读者写者问题 问题分析：写者与写者之间一定是互斥关系，写者与读者之间也一定是互斥关系。但是如果我们直接使用一个信号量处理读者和写者之间的互斥关系就会造成读者和读者之间发生互斥，这不是我们想看到的，所以我们需要一个特殊处理。 首先未来解决读者与读者不互斥，而读者和写者互斥，我们引入一个count变量，这个变量用于记录正在读取的变量，如国count等于0，则说明本进程是第一个访问的变量，这个时候给临界区使用P操作，然后使count++，最后退出的时候再次检测count，若count=0则自己是最后一个读进程，使用V操作进行解锁。这样就可以保证写进程和读进程的互斥，又能保证读进程之间不影响。 但是这有一个潜藏的隐患，假设写者1在运行到P(rw)的时候，突然遭遇进程切换，切换到了写者2，由于写者1还未运行到count++，所以count现在依旧是0，所以写者2执行P(rw)，由于写者1未执行V(rw)所以阻塞，这样的话就不满足读者与读者之间互相不干扰的条件，引起这种情况的原因主要是对于count的检测与操作并不能确保互斥，那怎样保证互斥呢？没错，我们使用信号量就是为了保证互斥性，所以我们引入一个信号量用于保证互斥性 正如图中所说，只要一直有读进程进入，那么rw一直不被释放，那么就会导致写进程一直阻塞等待，可能会导致“饿死”，这是我们不想看到的，所以我们希望当写进程要开始写的时候就不要让count继续增加了，所以我们需要让count增加的代码和写进程的写代码互斥。我们再次引入一个信号量进行互斥控制 这个问题的核心思想设置了一个计数器count用来记录当前正在访问共享文件的读进程数以及用互斥信号量解决无法“一气呵成”的代码 (3)吸烟者问题 问题分析：所有这种问题，第一步都是找关系，首先对于桌子的访问一定互斥的，然后只有供应者提供抽烟者1需要的素材，抽烟者1才能取走东西，这是一个同步关系，以此类推，可以推出三个同步关系，第三点就是吸烟者发出信号告诉供应者供应者才能将下一个组合放到桌上。 当然对于这个题，我们的桌子只有1，所以也没必要设置一个专门的互斥信号量进行互斥操作。 那如何实现轮流呢，我们可以使用一个数来表示需要提供谁的东西，并且每次提供后对i=(i+1)%3，这样就能保证循环了。 这个问题主要了解到可以用一个整形变量i来实现轮流的过程。 (4)哲学家进餐问题 问题分析：本题没有同步关系，每两个人之间的筷子相对于这两个人应该是互斥访问的，那我们使用五个互斥信号量尝试一下。 我们来讨论一下为什么单纯使用五个互斥变量不行，假设进程1在对左边的筷子的时候执行了P操作而这时候遇上进程切换进程2也同时对左边的筷子进行P操作，依次进行下去，所有人都拿到了一根筷子，然后也都等着其他进程把筷子让出来，这就导致了死锁，这当然不是我们想看到的，而想要解决这个问题我们有许多方法。比如我们可以设下条件，最多同时有四个人进入临界区，那么至少有一个人能够获得两根筷子，或者我们可以限定奇数的先拿左边的筷子，偶数的先拿右边的筷子，这样也能避免死锁，但是这些实现方案都太过复杂了。 我们重新分析为什么为什么我们之前的方法不行，因为我们在拿完左边的筷子的时候可能因为进程切换我们拿不到右边的筷子，这个问题归根结底就是取左边筷子和右边筷子不能“一气呵成”，我们前面已经多次遇到了不能一气呵成的代码的解决方式，没错我们再引入一个互斥信号量，确保拿左边筷子和拿右边筷子可以一气呵成的完成。那我们就得到了下面的代码。 哲学家问题给我们提供了一个方案解决可能导致的死锁的问题，通过一个互斥信号量保证每一个进程取所需要的东西时不会被打断。 5.7 管程之前我们介绍了信号量机制，也用他解决了非常多的进程同步相关的问题，但是我们能明显的发现一个问题，就是这个信号量同步机制，如果全都由程序员编程来实现的话实在是太复杂了，于是Brinch Hansen首次在程序设计语言（Pascal）中引入了“管程”成分。 管程的组成： 局部于管程的共享数据结构说明 对该数据结构进行操作的一组过程 对局部于管程的共享数据设置初始值的语句 管程有一个名字 管程的基本特征： 局部于管程的数据只能被局部于管程的过程所访问 一个进程只有通过调用管程内的过程才能进入管程访问数据结构 每次仅允许一个进程在管程内执行某个内部过程 各大高级语言都有管程的实现方式，具体的使用和实现可以自己去寻找官方文档或者自行搜索。 看起来这个管程的组成和特征比较难理解，但其实我们可以使用高级编程语言的方式来理解： 我们把管程看做是一个类，这个类中有一个私有的数据结构，只能通过这个类内部的实现的方法进行访问和修改，然后这个类定义了很多很多的方法确保能够访问数据结构。并且这个类每次都只允许一个进程进入使用里面的方法对这个数据结构进行操作，从而确保同步或者互斥访问。 5.8 死锁(1)死锁的定义各进程之间互相等待对方手里的资源，导致各进程都阻塞，无法向前推进 最典型的例子就是上面提到过的哲学家进餐问题，如果使用最初的版本就可能导致五个人都拿到左边的筷子，这样大伙都在等其他人放下筷子，从而使大伙都阻塞了。 明确三个概念：死锁，饥饿和死循环 (2)死锁产生的四个必要条件 互斥条件：对必须互斥使用的资源的抢夺才会导致死锁 不剥夺条件：进程保持的资源只能主动释放，不可强行剥夺 请求和保持条件：保持着某些资源不放的同时，请求别的资源 循环等待条件：存在一种进程资源的循环等待， 总结：对于不可剥夺资源的不合理分配，可能造成死锁 (3)死锁的解决方案总体来说分为三个部分： 预防死锁：破环死锁产生的四个必要条件中的一个或几个。 破坏互斥条件：如果把只能互斥使用的资源改造未允许共享使用，则系统不会进入死锁状态 破坏不可剥夺原则： 破坏请求和保持条件 破坏循环等待条件 避免死锁（银行家算法）（重点）  死锁的检测和解除  "},{"title":"线程（操作系统笔记3）","date":"2023-01-01T14:17:47.000Z","url":"/2023/01/01/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0-3/","tags":[["操作系统","/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"]],"categories":[["操作系统笔记","/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/"]],"content":"本篇笔记简单介绍一下线程，单独将线程拿出来说是为了避免和进程放一个笔记导致找不到哈哈，这篇较短是因为想把处理机调度单开一章。 第三章 线程3.1 线程的引入和定义有的进程可能想同时去做很多事，如果不引入线程想要达成这个效果可能就需要在单独开一个子进程，而我们知道进程之间的切换非常消耗资源需要重新创建进程，分配资源等，这就导致资源的浪费，系统并发度不高。 于是我们引入了线程，为了防止分配资源所消耗的资源，我们创建线程不需要额外分配资源，而是该进程的所有线程共享该进程的所有资源，这样线程就成了一个“轻量级进程”。线程成立一个基本的CPU执行单元，成为程序执行流的基本单位。 这样不仅各个进程之间可以并发，进程中的各个线程也可以实现并发，从而进一步提升了系统的并发度，而当我们引入线程后，进程只作为除CPU以外（如内存）的系统资源的分配单元。 3.2 引入线程后的变化 调度的基本单位：引入线程后，调度的基本单位从进程变为线程，线程仅作为资源分配的单位 并发性：不仅进程之间可以并发执行，进程中的线程与线程之间也可以并发，使操作系统拥有更好的并发性 拥有资源：进程拥有资源，而贤臣几乎不拥有资源，仅有一点必不可少的资源保证自己可独立运行 独立性：同一进程中的不同线程的独立性比不同进程之间的独立性低很多，因为同一进程中的线程共享资源 系统开销：创建进程时需要为他分配相应的资源，这远远大于给线程分配的资源 支持多处理机系统：传统进程只能无论多少处理机都只能一个进程分配到一个处理机，但是多线程则能让一个进程使用多个处理机同时处理 3.3 线程的实现线程的实现分为两种分别是： 用户级线程： 内核级线程： 两种线程组合的方式： 多对一模型 一对一模型 多对多模型 "},{"title":"处理机调度（操作系统笔记4）","date":"2023-01-01T14:17:47.000Z","url":"/2023/01/01/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0-4/","tags":[["操作系统","/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"]],"categories":[["操作系统笔记","/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/"]],"content":"本篇笔记将介绍一下处理机调度，这一章会涉及非常多的算法，评判标准，这一章考试的话，会考大题。 第四章 处理机调度4.1 处理机调度概念无论是进程还是作业，他们都是一堆一堆的进入计算机，但是CPU是有极限的，不可能同时处理所有的事，所以我们需要确定某种规则来决定处理的顺序，这就是处理机调度所需要研究的问题。 4.2 调度的三个层次 高级调度（作业调度）：由于内存空间有限，不可能将用户所提交的所有作业全部放入内存中进行运行，因此需要一定的规则将作业调入内存。主要目的是为了给作业建立相应的进程，使它们获得竞争处理机的权枥。高级调度主要是外存与内存之间的调度。 中级调度（内存调度）：等引入虚拟存储技术之后，操作系统会将暂时不能运行的进程调至外村等待，等需要时再重新调回内存，为了提高内存利用率和系统吞吐量，暂时调到外存等待的进程为挂起状态，PCB并不会一起调到外存，会常驻内存。被挂起的进程PCB会被放到的挂起队列。引入挂起态后进程状态变为七状态。 低级调度（进程调度）：主要任务使按照某种方法和策略从就绪队列中选取一个进程，将处理机分配给他，最基本的一种调度，频率也是最高的。（引入线程后就变成了线程调度） 三层调度联系与对比： 4.3 进程调度时机与切换过程进程调度一般发生在两个时机： 进程主动放弃（来自进程内部）： 进程正常终止，退出处理机 运行过程中发生异常终止，此时不得不主动退出处理机 主动的阻塞（比如等待I/O） 进程被动放弃： 分给进程的时间片用完 有更紧急的事情需要处理（如I/O中断） 有更高优先级的进程进入就绪队列 而有三个时间点一定不会发生进程调度： 在处理中断的过程中（会开关中断且是原语） 进程在操作系统内核程序临界区中（不能一个进程搁临界区写一半被切换出去吧） 原子操作过程中（原语） 进程的切换其实就是中断的过程加上进程调度，总结下来也就两点： 对原来运行进程各种数据的保存 对新的进程各种数据的恢复 需要注意的是进程切换是有代价的，过于平凡的进程调度切换回时系统的效率降低反而降低并发性 4.4 进程调度方式 非剥夺调度泛式（非抢占式）：只能由当前运行的进程主动放弃CPU（实现简单，适用于早期的批处理系统） 剥夺调度方式（抢占式）：可又操作系统剥夺当前进程的CPU使用权（可以优先处理更紧急的进程，也可实现让各进程按时间片流转的功能，适用于做分时操作系统，实时操作系统） 4.5 进程调度算法的指标 CPU利用率 CPU利用率=\\frac{忙碌的时间}{总时间} 系统吞吐量 系统吞吐量=\\frac{总共完成的作业数}{总共化类多少时间} 周转时间 周转时间 周转时间=作业完成时间-作业提交时间 平均周转时间 平均周转时间=\\frac{各作业周转时间之和}{作业数} 带权周转时间 带权周转时间=\\frac{作业周转时间}{作业实际运行的时间} 平均带权周转时间 平均带权周转时间=\\frac{各作业带权周转时间之和}{作业数} 等待时间 等待时间=处于等待处理机状态时间之和 相应时间 相应时间=用户提交的时间点-首次相应的时间点 4.6 进程调度算法这一块涉及非常非常多的题，无论期末还是考研都是重中之重。 先来先服务（FCFS） 算法思想：主打的就是公平，谁来都得排队 算法规则：按照先后顺序进行服务 适用：作业调度的话看谁见到后备队列，进程调度则看谁先到就绪队列 是否抢占：非抢占式算法 优点：公平，实现简单 缺点：排在长作业后面的短作业需要较长等待时间，带权周转时间很打 是否会导致饥饿：不会 短作业优先（SJF） 算法思想：最求最少的平均等待时间，最少的平均周转时间，追杀哦的平均带权周转时间 算法规则：最短（指要求服务时间最短）的作业/进程优先的到服务 适用：作业调度就是短作业优先（SJF），进程调度就是（SPF） 是否抢占：是非抢占式算法，但也有抢占式版本：最短剩余时间优先算法（SRTN） 优点：“最短的”平均等待时间、平均周转时间 缺点：不公平。对短作业有利，长作业不利，可能会导致长作业长期的不到服务，也就是导致饥饿 是否会导致饥饿：会，如果源源不断地有短作业/进程到来，可能使长作业/进程长时间地不到服务，产生饥饿，如果一直地不到服务则称为饿死 高响应比优先（HRRN） 算法思想：综合考虑作业/进程地等待时间和要求服务时间 算法规则：在每次调度时计算各个作业进程地相应比，选择最高的为其服务 相应比=\\frac{等待时间+要求服务时间}{要求服务时间} 适用：既可用于进程调度，也可用于作业调度 是否抢占：是非抢占式算法 优点：综合考虑不了等待时间和运行时间，结合了前两个算法的优点，也解决了饥饿 缺点：无明显缺点 是否会导致饥饿：不会 前三个算法的评价：这三个算法主要关心对用户的公平性、平均周转时间、平均等待时间等指标，并不关心相应时间，也不区分任务的紧要程度，导致交互性很差，适用于早期的批处理系统。 时间片轮转（RR） 算法思想：公平地轮流为各个进程服务，让每个进程在一定时间间隔内都可以得到相应 算法规则：按照各进程到达就绪队列地顺序，轮流让各个进程执行一个时间片。若进程在一个时间片执行不玩，也要剥夺处理机，将进程重新放到就绪对立对位重新排队 适用：只用于进程调度（只有作业放入内存建立了相应的进程后，才能分配处理机时间片） 个人理解：你不能每次都调一点作业的东西放进内存吧，这样大伙资源都不够，大伙都运行不了（都得死（bushi）） 是否抢占：抢占式算法，通过时钟装置发出的时钟中断来通知CPU时间片已到，到了还没运行完，就会强行剥夺处理机使用权。 优点：公平，响应快，适用于分时系统 缺点：由于高频率的进程切换，因此有一定开销，不区分任务紧急程度 是否会导致饥饿：不会 优先级调度算法 算法思想：实时系统需要根据任务的紧急程度来决定处理顺序 算法规则：调度时选择优先级最高的作业/进程 适用：即可用于作业调度，也可用于进程调度 是否抢占：抢占式算法，通过时钟装置发出的时钟中断来通知CPU时间片已到，到了还没运行完，就会强行剥夺处理机使用权。 优点：公平，响应快，适用于分时系统 缺点：由于高频率的进程切换，因此有一定开销，不区分任务紧急程度 是否会导致饥饿：不会 多级反馈队列调度算法 算法思想：对其他算法的折中权衡 算法规则： 设置多级就绪队列，各级队列优先级从高到低，时间片从小到大 新进程到达时先进入第一级队列，按FCFS原则排队等待被分配时间片，若用完时间片进程还未结束，则进程进入下以及队列队尾 只有等k级队列为空时，才会为k+1级对头的进程分配时间片 适用：进程调度 是否抢占：抢占式算法，在k级队列的进程运行过程中，若更上级的队列中进入一个进程，会先完成优先级更高的队列，因此进程会被抢占 优点：相对公平，每个新到达的进程很快能得到响应，不必实现估计进程得时间，短进程只用较少时间就可完成，不必估计运行时间 缺点：由于高频率的进程切换，因此有一定开销，不区分任务紧急程度 是否会导致饥饿：会 后三个算法的评价：这三个算法更注重系统的响应时间、公平性、平衡性，满足欢呼时系统需求，适用于交互式系统 注：本章算法等知识需要做题巩固。"},{"title":"进程的描述与控制（操作系统笔记2）","date":"2023-01-01T04:10:47.000Z","url":"/2023/01/01/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0-2/","tags":[["操作系统","/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"]],"categories":[["操作系统笔记","/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/"]],"content":"本篇笔记进入操作系统的第一个功能处理器管理，而处理器管理重要功能就是对进程的管理。本篇对进程的描述和管理进行讲解。 第二章 进程的描述与控制2.1 进程的引入和定义引入进程是为了方便操作系统对多道程序进行并发执行，系统为每个运行的程序配置一个数据结构（程序和进程不是一一对应的关系），称为进程控制块（PCB），用来描述进程的各种信息。 程序段，数据段，PCB三部分组成了进程实体，我们把进程实体简称为进程。 2.2 进程的特征 动态性：进程是程序的一次执行过程，动态产生、变化和消亡的。 并发性：内存中有多个进程实体，各进程并发执行。 独立性：进程独立运行，独立获得资源，独立接收调用（是资源分配的基本单位，如果不引入线程也是处理机调度的基本单位）。 异步性：各进程独立向前推进，速度不可预知。 结构性：每个进程都会配置一个PCB。 2.3 进程的状态基本状态： 运行态：占有CPU，并在CPU上运行 就绪态：具备运行条件，由于CPU没空，暂时不能运行 阻塞态：因等待某一时间暂时不能运行 另外两张状态： 创建态：进程正在被创建，操作系统为进程分配资源，初始化PCB 终止态：进程正在从系统中撤销，操作系统会回收进程拥有的资源、撤销PCB 2.4 进程控制进程控制就是实现进程状态的转换。 进程控制是通过原语来实现的。 而源于是通过开关中断来实现的。 原语的执行必须一气呵成，不可中断。 对于进程控制相关的原语： 进程的创建 申请空白PCB 分新进程分配资源 初始化PCB 将PCB加入就绪队列 进程的终止 从PCB的集合中找到终止进程的PCB 若进程正在运行，立即剥夺CPU，将CPU分配给其他进程 终止其所有子进程 将所有资源归还父进程或操作系统 删除PCB 进程阻塞 找到要阻塞进程的PCB 保护现场，设置为阻塞态，停止进程运行 将PCB插入相应等待队列 进程唤醒 找到要唤醒进程的PCB 将其从等待序列中溢出，变为就绪态 加入就绪队列等待被调度 进程切换 将运行环境信息存入PCB PCB移进相应队列 选择另一个进程执行，并更新其PCB 根据PCB恢复新进程所需运行环境 2.5 进程通信进程通信指的是进程之间的信息交换。 一个进程并不能直接访问另一个进程的地址空间。但是进程之间的信息交换是必须的。 经过发展有利能传送大量数据的高级通信机制，可归结为4类： 共享存储器系统：共享一块大家都可以访问的空间，一次只能有一个进程进行读或写操作 基于数据结构的共享：由程序源对空想数据结构进行设置和对进程间同步进行处理，OS只负责提供共享存储区，是一种低级通信方式 基于共享存储区的共享：在内存中画出一块共享存储区，数据形式存放位置均由进程控制，是一种高级通信方式 管道通信系统： 指用于连接读写进程的一个共享文件。和共享存储器系统一样需要呼出访问，可以实现半双工通信，同时他确保两个进程达成同步，写进程写一定数量后便会休眠，直到读进程取走数据，读进程读完后也需要进入休眠，直到写进程再次写入数据。相比于共享存储器，管道系统两个进程之间一定会确定对方存在。 消息传递系统：通过操作系统提供的“发送/接收消息”的原语实现，发送放将消息头写好，接收方通过消息头读取或寻找哪个消息是自己的，网络上的报文传输也是一样的道理。同时他也分两类： 直接通信方式：发送方发送的消息直接放入接收方的消息缓冲队列。（QQ式） 间接通信方式：发送方先将消息发送给中转站，等接收方有时间了在去中转站找。（油箱式） 客户机服务端式：使用套接字或远程过程调用和远程方法调用 "},{"title":"操作系统概述（操作系统笔记1）","date":"2022-12-31T12:32:47.000Z","url":"/2022/12/31/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0-1/","tags":[["操作系统","/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"]],"categories":[["操作系统笔记","/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/"]],"content":"本系列笔记是为了对操作系统相关的知识点进行记录，本篇文章主要记录概述相关内容。 第一章 操作系统概述1.1 操作系统定义操作系统是一组用于控制和管理计算机系统软件和软件资源，合理地对各类作业进行调度，以及方便用户使用地集合。 简单点来说就是为了让人们更方便地使用计算器而不是对着一堆电路发呆而专门设计地一层软件。他能帮忙处理很多需要与硬件交互的事件。 1.2 操作系统地位配置在计算机硬件上的第一层软件。 1.3 操作系统的四大基本特征（重要） 并发：两个或多个活动在同一给定的时间间隔中进行。 共享：计算机系统的资源可以被多个进程公用。 异步：进程的执行并不是一气呵成，无论是为了实现并发还是达成交互性，进程在执行时总是断断续续的，所以进程的运行速度并不可预知。 虚拟：通过时分复用，空分复用等技术，将一个物理实体转换成逻辑对应物，比如本来只有一根线来传递信息，通过不同频道让观众以为有好几根管道传递着不同的信息。 最基本特征：并发，共享（互为存在条件） 1.4 主要功能也就是后面我们要介绍的主要内容。分别分为四个模块： 处理机管理：包括进程控制、同步、通信，以及导致的死锁问题，作业调度，进程调度。 存储器管理：内存分配回收，内存保护，地址映射，内存扩充 设备管理功能：缓冲管理，设备分配，设备处理 文件管理功能：文件存储空间管理，目录管理，文件的读写管理和保护 接口管理功能： 用户接口：便于用户直接或间接控制自己的作业 联机用户接口：CMD 脱机用户接口：.bat文件 图形用户接口：采用图形化操作界面，比如双击文件夹就打开了 程序接口：用户程序在访问系统资源而设置的 如使用各种外部设备、申请分配和回收内存及其它各种要求 1.5 操作系统发展（考试重要） 人工操作阶段（无操作系统）：缺点：用户独占计算机，人机速度矛盾资源利用率低。 批处理系统： 单道批处理系统：脱机输入，并控制作业的输入输出（操作系统雏形），内存中仅有一道程序 优点：缓解了人机矛盾，资源利用率有所提升 缺点：资源利用率依然很低 多道批处理系统：内存中多道程序，在CPU中交替进行，初步实现了并发 优点：多道程序并发执行，资源利用率高 去点：用户响应时间长，无人机交互，无法跟踪程序运行情况 分时操作系统：以时间片为单位轮流为各个用户或作业提供服务。 优点：实现了人机交互 缺点：对于突发情况难以及时响应处理 实时操作系统：能够优先响应紧急任务 硬实时系统：某个动作必须在规定时间内完成，否则后果严重 软实时系统：可以偶尔违反实时响应，不会造成重大后果 优点：解决了分时系统无法响应紧急情况的问题 微机操作系统：个人计算机操作系统，由于个人计算机飞速发展种类多样 单用户单任务：MS-DOS 单用户多任务：Windows系列 多用户多任务：UNIX，Windows NT/Server 网络操作系统：把计算机网络中的各台计算机有机的结合起来，对网络资源进行管理和控制 嵌入式操作系统：为了完成特定某个功能而实现的操作系统，不具有通用性，Android，iOS等。 分布式操作系统：系统中的各计算机相互协同并行完成同一任务，包含通信管理功能，资源管理功能，进程管理功能。 1.6 操作系统运行机制 用户态转核心态：只能通过中断来实现 核心态转用户态：执行一个特权指令 1.7 中断和异常中断：为了实现多道程序提高资源利用率，而程序切换需要进入核心态，为了从用户态进入核心态，所以引入中断操作。 当发生中断，意味着需要操作系统介入管理工作，cpu会立即进入核心态。 中断分为两种： 内中断（异常）：来自CPU内部，包括程序出错或者程序自愿中断 外中断（中断）：来自CPU外部，包括外设要求，人工干预（用户强行终止一个进程） 中断处理过程： 关中断：CPU响应中断，需要保护程序的现场状态，这个时候CPU不应该响应更高级中断源的中断请求，否则现场保护不完整。 保存断点：为了保证能回到原来的程序，将断点保存起来。 引出中断服务：取出中断服务程序的入口地址送入程序计数器。 保存现场和屏蔽字：进入中断服务程序后首先要保存现场，现场信息一般指的是程序状态字、中断屏蔽寄存器和CPU中某些寄存器的内容。 开中断：保护现场完毕就可以响应更高级的中断请求了。 执行中断服务程序：中断系统的核心，不同的中断请求对应不同的中断服务程序。 关中断：执行完中断服务程序后需要恢复现场，这个时候也不允许响应更高级中断源的中断请求。 恢复现场和屏蔽字：将现场和屏蔽字恢复到原来的状态。 开中断及中断返回：恢复完现场后可以响应更高级中断源的中断请求，并回到程序断点处继续执行源程序。 1.8 系统调用用户程序通过系统调用（程序接口）请求获得操作系统的服务。 系统调用会产生中断使处理器从用户态转为核心态。 系统调用可分为一下几类： 设备管理：完成设备请求、释放、启动等功能 文件管理：文件的读写、创建删除等功能 进程控制：包括进程的创建、撤销、阻塞、唤醒等功能 进程通信：完成消息传递、信号传递等功能 内存管理：包括内存分配、回收等功能 系统调用发生在用户态，对系统调用的处理发生在核心态。"},{"title":"数据结构笔记","date":"2022-12-25T06:19:47.000Z","url":"/2022/12/25/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%94%E8%AE%B0/","tags":[["数据结构","/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"],["算法","/tags/%E7%AE%97%E6%B3%95/"]],"categories":[["数据结构笔记","/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%94%E8%AE%B0/"]],"content":"本笔记是我大一的时候自学数据结构所总结的笔记。内容不多，深度也比较低，想对数据结构进行精进的大可不必看这个，如果只是为了应付学校的考试或者入个门，这个倒是足够了。 当时也是刚接触到md，所以有些地方写的不太好，请谅解 第一章：数据结构绪论逻辑结构与物理结构逻辑结构逻辑结构：是指数据对象中数据元素之间的相互关系面向问题的。 逻辑结构可以分为四类。 集合结构即数据除了在同一集合中无其他关系。 线性结构数据元素之间是一对一关系 树形结构数据元素之间呈现一对多关系 图形结构数据元素之间呈现多对多关系 物理结构线性存储数据均放在连续的存储空间中。可以进行随机访问。链式存储 链式存储把数据存储在任意存储单元，各个数据的关系通过指针来表示 第二章：算法概念说白了就是解决问题办法 特性基本的输入输出有穷性指算法在执行有限的步骤之后，自动结束而不会出现无线循环，并且每一个步骤在可接受范围内完成 确定性算法每一步都具有确定的定义，不能同一种情况进入不同的分支 可行性算法的每一步都必须可行 设计要求正确性算法的正确性是指算法至少应该具有输入、输出和加工处理无歧义性，能正确反应问题的需求、能够的到问题的正确答案 本人翻译：就是算法算出来的必须是对的 健壮性当输入数据不合法时，算法也能做出相关处理，而不是产生异常或莫名奇妙的结果 本人翻译：就是当用户点一份蛋炒饭时程序不会炸 可读性算法设计的另一目的是为了便于月的、理解和交流 本人翻译：说白了就是要让人能看懂 时间效率高和存储量低本人翻译：跑程序时电脑不卡，跑的快，又不占内存 算法优劣的判断方法时间复杂度 时间复杂度所需消耗的时间即基本操作执行次数 时间复杂度的计算该方法就是大O阶表示法的计算方法 （1）用常数 1取代运行时间中的所有加法常数 （2）在修改后的运行次数函数中，只保留最高阶项 （3）如果最高阶项存在且不是 1，则去除与这个项相乘的常数 常用时间复杂度的比较 空间复杂度运行完一个程序所需内存的大小 注：感觉用得不多，目前了解定义就行 第三章：线性表定义零个或多个数据元素的有限序列 线性表的顺序存储结构定义用一段连续得存储空间对数据进行存储 本人翻译：说白了就是数组 特性拥有随机访问特性 时间复杂度(1)对于存取操作 线性表的顺序存储结构，对于存取操作，其时间复杂度为O(1) 因为元素位置可以直接计算得到 (2)对于插入和删除操作 对于插入和删除操作，其时间复杂度为O(n)因为插入或删除后，需要移动其余元素 使用场景因此，线性表顺序存储结构比较适用于元素存取操作较多，增删操作较少的场景 线性表的链式存储结构定义一个或多个结点组合而成的数据结构称为链表 结点结点一般由两部分组成 数据域用来装需要存储的数据 指针域存储指向下一个结点的指针 头结点为了能更加方便地对链表进行操作，会在单链表的第一个结点（即头指针）前附设一个结点，称为 头结点 该结点不装任何实际数据方便操作 注：并非每个链表都有 头指针指向第一个结点的指针称之为头指针 注：不一定是头指针 单链表单链表的时间复杂度（1）存取操作 而对于单链表结构，假设需要获取第 i 个元素，则必须从第一个结点开始依次进行遍历，直到达到第 i 个结点。因此，对于单链表结构而言，其数据元素读取的时间复杂度为O(n) 注：你需要从第一个开始一个一个去找，而不是通过下标一下子找到，所以时间复杂度为O(n) （2）插入删除 对其任意一个位置进行增删操作，其时间复杂度为O(n) 注：之所以还为O(n)主要原因是你需要找到所需插入的元素 链式表与顺序表的优缺点缺点链式表存取操作的时间复杂度更高 优点虽然插入删除两种时间复杂度都为都为O(n)，但是如果需要插入删除，顺序表由于每次插入删除都要移动其他元素，所以每次都为O(n)，而链式表第一次插入时查找到所需要的位置，之后的插入删除操作仅需要修改一下指针，所以之后的插入删除操作的时间复杂度为O(1) 链式表与顺序表的选择经常进行存取操作时，可选择顺序表 经常进行插删操作时，可选择链式表 循环链表定义将单链表中的终端结点的指针端由空指针改为指向头结点就使整个单链表形成一个环这种头尾相接的单链表称为单循环链表，简称 循环链表 个人翻译：就是把链表最后的结点的下一个结点指向第一个结点 注：头结点的作用是判断首尾，并非每一个循环链表都需要头结点 作用循环链表要好使用需要设置一个尾指针指向循环链表的最后一个结点，这样便可以使寻找尾结点的时间复杂度调为O(1),并且寻找头结点也只需要移动到下一个或下下个结点，时间复杂度也为O(1) 双向链表定义在单链表的每个结点中，再设置一个指向其前驱结点的指针域 双向循环链表既然单链表有循环链表，那双向链表自然有双向循环链表 双向循环链表重点双向循环链表最重要的是在插入删除时的操作顺序 插入时： 删除时： 删除时记得要将删除的结点释放 第四章：栈与队列栈定义栈是限定仅在表尾进行插入和删除操作的线性表 个人翻译：看过弹夹吗，他只会在装弹口进行装弹和弹出操作，这就是栈 允许插入删除操作的一端为栈顶，另一端为栈底 栈的插入操作称为入栈 栈的删除操作称为出栈 不含任何任何数据元素的栈称为 空栈 特性栈最显著的特性就是先进后出 栈的分类顺序栈可以使用线性表的顺序存储结构（即数组）实现栈，将之称之为顺序栈 所有顺序存储的结构都有一个很致命的问题就是需要事先确定一个固定的长度，固定长度所导致的问题就是内存空间的浪费或是内存的溢出 同样的他们也都有一个优势就是存取定位非常方便 链式栈可以使用单链表实现栈，称之为链式栈 所有链式存储的结构也都有一个很致命的问题就是在每一个数据结点中都需要增加一个指针域，这会增加内存的开销，但好处是栈的长度一般来说是无限的 时间复杂度由于插入操作皆是在队尾进行，所以当有一个指针一直指在队尾时无论是顺序表还是链式表时间复杂度都为O(1) 栈的应用四则运算方法： 一、首先通过栈将中缀表达式转化为后缀表达式 规则： 数字直接加入后缀表达式 如果是‘(’, 入栈 如果是‘)’, 则依次把栈中的运算符加入后缀表达式，直到出现‘(’并从栈中删除它 如果是运算符 + - * / a.栈空或者栈顶元素为‘(’, 入栈 b.高于栈顶元素优先级，入栈 c.否则依次弹出栈顶运算符，直到遇到一个优先级小于它的运算符或者是遇到‘(’为止 遍历完成后，如果栈非空则依次弹出所有栈顶元素加入到表达式当中 二、通过栈得到运算结果 从左到右,遇到运算符就弹出相应的运算数,运算后再把结果入栈.最终结果就是栈顶数的值. 队列定义队列是允许在一端进行插入操作，而在另一端进行删除操作的线性表。 允许删除的一端称为队头 允许插入的一端称为队尾 特性队列是先进先出 队列分类顺序队列 链式队列 循环队列顺序队列会造成一个问题，就是假溢出，队头元素出栈后，并不能像顺序表一样，将剩下的元素集体往前面移一个地址，就会造成，队列前面明明有大量的空间未被使用但是元素排到队尾造成假溢出，为了解决这个问题就引入了循环链表的概念。 定义将头尾相接的顺序存储结构称为循环队列 当头尾相接时虽然解决了假溢出的问题，但是同样也产生了一个问题，无法判断队列是否已满。 判断队列是否已满的方法第一种设置一个标志变量，当front==rear，且flag=0时为队列空 当front==rear，且flag=1时为队列满 第二种当队列空时，front==rear，当队列满时，我们修改它的条件，保留一个元素空间。也就是说，队列满是，数组中还有一个空闲单元。 所以循环队列求队伍长度（rear-front+maxsize）%maxsize通过这个公式也可判定队列是否满了 第五章：串定义串是由零个或多个字符组成的有限序列，又名字符串 串中的字符数目称为串的长度 零个字符的串称为空串 分类串与线性表很像，只是限定了串中的元素必须为字符 故字符串的分类与线性表是一样的 串分为顺序存储结构以及链式存储结构 注：这章有个模式匹配算法，比较复杂，有机会的话再总结成一篇 第六章：树定义树是n个结点的有限集 n=0时称为空树 注：个人感觉这个定义啥也没说，所以要判断一个东西是不是树，应该用下面的特点进行判断 特点有且仅有一个特定的称为根的结点 当n&gt;1时，其余结点可分为m（m&gt;0）个 互不相交的有限集，其中的每一个集合本身又是一颗树，并且称为根的子树 基本术语结点拥有的子树数称为结点的度 度为0的结点称为叶节点或终端结点 个人翻译：该结点下面没有其他结点了，这个结点就是终端结点 度不为0的结点就是非终端节点或分支节点 除根节点以外的分支结点称为内部结点 树的度就是内部结点中度的最大值 结点之间的关系结点的子树的根称为该结点的孩子，该节点称为孩子的双亲。 个人翻译：与某个结点相连的结点中，在这个结点上面的就是该结点的双亲，在这个结点下面的就是这个结点的孩子 同一个双亲的孩子互相之间互称兄弟 结点的祖先是从根到该节点所经分支上的所有节点 以某节点为根的子树中的任一结点都称为该节点的子孙 树的层次 有序树如果将树中的结点的各子树看成从左至右是有次序的，不能互换的，则称该树为有序树，否则称为无序树 森林森林时m颗互不相交的树的集合 二叉树（重点）定义二叉树是n个结点的有限集合，该集合或者为空集（称为空二叉树），或者由一个根结点和两颗互不相交的，分别称为根结点的左子树和右子树的二叉树组成 个人翻译：除了空集这个比较特殊的二叉树，如果看到一颗树它的所有结点的子节点最多只有两个，那这个树就是二叉树 特点 每个结点最多只能有两棵子树 左子树和右子树是有顺序的，次序不能任意颠倒 即使树中某结点只有一棵子树，也要区分它是左子树还是右子树 特殊二叉树满二叉树定义：只含度为0和2的结点且度为0的结点只出现在最后一层的二叉树称为满二叉树 完全二叉树定义：对任意一颗满二叉树，从它的最后一层的最右结点起，按从下到上、从右到左的次序去掉若干个结点后所得到的二叉树称为完全二叉树 特性1.在二叉树的第i层上至多有$2^{i-1}$个结点 2.深度为k的二叉树至多有$2^k-1$个结点 3.对任何一颗二叉树T，如果其叶子结点点数为$n_0$，度（即子结点数)为 2 的结点数为$n_1$，则$n_0=n_1+1$ 4.具有n个结点的**完全二叉树**的深度$[log2n]+1$ 注：$[x]$表示不大于x的最大整数 5.如果对一棵树有n个结点的完全二叉树（其深度为$[log2n]+1$的结点按层次编号，从左到右，对任一结点i有 a.如果i=1，则该结点为根结点，无双亲，若i&gt;1，则其双亲为i/2 b.如果2i&gt;n，则节点i无左孩子（结点i为叶子节点），否则其左孩子为2i c.如果结点2i+1&gt;n，则节点i无右孩子，否则其右结点为2i+1 二叉树的遍历二叉树遍历均有两种比较实用的算法：一种为递归算法，一种则是非递归的算法 先序遍历如果二叉树为空，则进行空操作，否则进行以下操作： 1.访问根节点 2.先序遍历左子树 3.先序遍历右子树 递归算法： 思路：运用递归的思想，如果左子树不为空就一直访问左子树，直到左子树为空，左子树为空则会回到上一次递归，访问右子树，以右子树为根结点继续优先访问左子树，直到左子树为空，又跳出本次递归，然后一层一层的解递归，就能最终将整颗二叉树访问完毕。 非递归算法： 思路：非递归算法需要用到之前所学到的线性表的栈，整体思路则是将根结点放入栈中，访问左节点，将左节点放入栈中，只要左节点不为空则一直访问左节点，并将它放入栈中，当左节点为空则访问这个节点的右结点，并将该节点放入栈中，然后继续访问右结点的左节点，然后将右结点放入栈中，直到访问到叶子节点，则取出栈头元素，访问其右结点 中序遍历1.中序遍历所有左子树 2.访问根节点 3.中序遍历所有右子树 两种算法思路与先序遍历基本一致，此处不再赘述，只提供相应代码 递归算法： 非递归算法： 后序遍历1.后序遍历左节点 2.后序遍历右结点 3.访问根节点 递归算法： 非递归算法： 层次遍历二叉树的层次遍历就是按照二叉树的层次，从上到下，从左到右依次遍历，为了实现这种遍历方式则需要用到之前所学到的队列 思路：首先将根节点放入队列，然后出队，访问根节点，将根节点的左孩子右孩子依次放入队列中，再依次从队列中取出各个结点，重复刚才的操作，直到队列为空。 线索二叉树由于二叉树中有些节点或是左节点为空，或是右结点为空，或是都为空，会导致二叉树对内存的浪费，于是提出了线索二叉树的概念。 定义利用这些空链域存放在某种遍历次序下该结点的前驱结点和后继结点的指针，这些指针称为线索，加上线索的二叉树称为线索二叉树。 事实上如果只是为了应付考试，只需要知道线索二叉树怎么画就行了 线索二叉树的画法重要规则如果一个结点的左孩子为空，则指向它的前驱结点。 如果一个结点右孩子为空，则指向它的后继。 举个例子 假设要画这个二叉树的中序二叉树 先写出它中序遍历的结果：DFBACE 然后画出每个结点的结构 注：结点名字左右两边的数字作为标志，该节点如果有左孩子，左标志为0，否则为1，右孩子亦然 接下来通过重要规则以及中序遍历结果连线就完事了 树，森林，二叉树转换我自己是看的这篇文章，写的真不错啊（主要我懒得画图）  哈夫曼树以及哈夫曼编码这位大佬通过举例子的方式讲的哈夫曼树以及哈夫曼编码，仔细看很容易看懂（懒得画图，开摆了）  第七章：图定义由顶点的有穷非空集合和顶点之间的边的集合组成。 个人翻译:点之间连着线就是图 数据结构间的区别线性表：一对一，只有前驱和后驱 树：一对多，一个结点对应多个子节点，一个根节点 图：多对多，多个顶点对应多个顶点 图的分类无向图若顶点$v_i$到$v_j$之间的边没有方向，那么这条边就是无向边 如果图中任意两个结点之间的边都是无向边，则称为无向图 无向图顶点的边数叫做顶点的度 有向图若从顶点$v_i$到$v_j$的边有方向，则称这条边为有向边，也称为弧 如果图中任意两个顶点之间的边都是有向边，则称该图为 有向图 指向自己的边的条数称为顶点的入度，由自己指出去的边的条数称为出度 简单图在图中，若不存在顶点到其自身的边，且同一条边不重复出现，则称这样的图为简单图 无向完全图在无向图中，如果任意两个顶点之间都存在边，则称该图为无向完全图 有向完全图在有向图中，如果任意两个顶点之间都存在 方向互为相反 的两条弧，则称该图为有向完全图 权有些图的边或弧具有相应的权值，这种与图的边有关的数被称为权 带权的图一般被称之为网 个人翻译：好比两个点之间有路，路就是图的边，而距离就是这条边的权 连通图图中顶点间存在路径，两顶点存在路径则说明是连通的 没有重复顶点的路径称为简单路径 无向如果无向图中任意两个结点是连通的，则称之为连通图 有向有向连通图分为弱连通，单向连通，强连通 弱连通：有向图的底图（无向图）是连通图，则是弱连通图 单向连通：有向图中，任意两个结点至少有一个到另一个是可达的，则是单向连通图 强连通：有向图中，任意两个结点互相可达，则该图为强连通图 图的存储结构计算机只认识01，所以我们不可能在cpu上面画一个图然后逼着cpu完成运算 于是便有了图的存储结构，和线性表一样，图的存储结构也分为两种分别是：邻接矩阵，邻接表 邻接矩阵图的邻接矩阵存储方式是用两个数组来表示图。一个一维数组存储图中顶点信息，一个二维数组(称为邻接矩阵)存储图中的边或弧的信息。 邻接表用单链表和顺序存储的方式来存放图 这个存储结构比较复杂，我觉得我会讲错，所以摆烂了，想要学习的可以去看看这位大佬的  图的遍历图的遍历也是有两种方法，分别是深度优先遍历，广度优先遍历 深度优先遍历由名字可得优先向前访问 首先以一个未被访问过的顶点作为起始顶点沿当前顶点的边走到未访问过的顶点 当没有未访问过的顶点时则回到上一个顶点继续试探别的顶点，直至所有的顶点都被访问过 广度优先遍历同样由名字可得优先对一个结点指向的其他所有未被访问的结点进行遍历 依次将访问到的顶点放入队列，然后依次访问他们的下一个结点，访问到的均放入队列 直到队列为空，整个图访问结束 可以用来解最短路径问题 最小生成树最小生成树包含两种算法，分别是普利姆算法和克鲁斯卡尔算法，由于我实在懒的画图所以也粘一篇大佬的文章了  拓扑排序这个很简单，只要按着以下步骤走就没问题 1.寻找未被指向的结点，将他取出（若有多个选其一） 2.去除取出的结点和与它相连的线 3.执行第一步 4.直到整个图都完成排序"},{"title":"C#知识(9)","date":"2022-12-24T15:29:46.000Z","url":"/2022/12/24/CS%E7%9F%A5%E8%AF%86/CS%E7%9F%A5%E8%AF%86-9/","tags":[["C#","/tags/C/"]],"categories":[["C#知识","/categories/C-%E7%9F%A5%E8%AF%86/"]],"content":"本节主要内容：协程及Unity中的用法 1.协程（1）使用本章的内容将紧扣unity中的协程进行讲解，先来看看一个协程应该怎么使用。 上面的就是协程的使用方式。 （2）优点然后我们来聊一聊协程的好处，在搜资料的时候我看到一个有趣的例子，你去某个办事处办事，此时办事处是cpu每个人办的事就是一个一个线程，办事处只有一个员工（对应cpu在同一个时间只能进行一个线程），当这个员工要从一件事转头去做另一件事，自然要做许多事，比如先暂停上一件事，然后把上一件事资料整理好，方便下次做这件事的时候开始，然后要加载另一件事所需的资源，所以线程之间的切换是很耗费时间的，但是，如果你自己能仿制办事处的办事方法，就不需要再到办事处浪费时间了，这就是协程的好处。 让原来要使用异步 + 回调方式写的非人类代码, 可以用看似同步的方式写出来。能够分步做一个比较耗时的事情，如果需要大量的计算，将计算放到一个随时间进行的协程来处理，能分散计算压力 （3）缺点我们可以看到我们上面的程序，需要再返回时new一个对象，如果再程序中大量的创造对象会引发GC，同时，如果激活的协程较多，就可能会造成多个协程挤在同一帧执行，导致卡顿。 （4）协程的运行时间 所有使用到yield的都是协程，协程不是线程，和update和start一样在主线程上运行。 （5）协程结束方式1.StopCoroutine，不解释，上面有用法，别用错了 2.stopAllCoroutines暂停的是当前脚本下的所有协程 3.移除脚本，移除物体，禁用物体（实测禁用脚本屁用没有） （6）中断函数类型null 在下一帧所有的Update()函数调用过之后执行 WaitForSeconds() 等待指定秒数，在该帧（延迟过后的那一帧）所有update()函数调用完后执行。即等待给定时间周期， 受Time.timeScale影响，当Time.timeScale = 0f 时，yield return new WaitForSecond(x) 将不会满足。 WaitForFixedUpdate 等待一个固定帧，即等待物理周期循环结束后执行 WaitForEndOfFrame 等待帧结束，即等待渲染周期循环结束后执行 StartCoroutine 等待一个新协程暂停 WWW 等待一个加载完成，等待www的网络请求完成后，isDone=true后执行 （7）执行顺序开始协程-&gt;执行协程-&gt;遇到中断指令中断协程-&gt;返回上层函数继续执行上层函数的下一行代码-&gt;中断指令结束后，继续执行中断指令之后的代码-&gt;协程结束 协程如果还有问题可以看看:，我就是看这篇文章总结出来的。"},{"title":"C#知识(8)","date":"2022-12-24T15:29:43.000Z","url":"/2022/12/24/CS%E7%9F%A5%E8%AF%86/CS%E7%9F%A5%E8%AF%86-8/","tags":[["C#","/tags/C/"]],"categories":[["C#知识","/categories/C-%E7%9F%A5%E8%AF%86/"]],"content":"本节主要内容：垃圾回收机制和相关重要算法 本章内容大量参考： 1.GC（垃圾回收机制）当我们进行C++的开发的时候，我们有时需要使用new关键词在堆上手动开辟空间，同时也会用到delete来进行空间的释放，在C里面则是使用malloc和free关键词，但是当我们使用C#时我们大部分时候并不需要去管理堆上的内存，就好像系统帮我们完成了开辟和回收。 其实C#作为一门托管型语言，托管代码在clr中运行，clr会自动惊醒垃圾回收等服务，所以我们才可以放心的随便创建引用值而不用担心内存遗漏。接下来简单介绍以下GC的机制。 （1）标志压缩算法该算法分三个步骤： 1.先假设堆中所有对象都可以回收 2.然后找出不能回收的对象 3.最后堆中没有打标记的对象都是可以被回收的 4.此时堆中对象不连续，移动这些对象，使他们重新从基地址开始连续 经过这四步处理后，可以继续采用前面的堆内存分配方法，即仅用一个指针记录堆分配的起始地址就可以。 主要处理步骤：将线程挂起→确定不能回收的对象→对象回收→堆压缩→指针修复。 此处有两个问题： 1.怎么确定哪些对象不能回收？ 答：首先GC从已经初始化的静态变量或者线程人在使用的对象（stack+CPU register）确定roots，通过复杂的引用关系，从roots出发开始寻找，如果能通过相互引用到达的引用则标记为不能回收的对象，剩余的对象则可以回收。 2.指针修复干了什么？ 答：我们知道引用对象的存储方式是在栈上存储一个引用，这个引用其实就类似一根指针，他指向堆中相对应的内存，而当我们回收完并对堆进行压缩后，这些指针之前指的就会变成错误的地址，所以要进行修复。 Debug和release执行模式之间稍有区别，release模式下后续代码没有引用的对象是可以回收的，而debug模式下需要等到当前函数执行完毕，这些对象才会成为可回收的，目的是为了调试时跟踪局部对象的内容。 一些问题：Pinned objects指分配之后不能移动位置的对象，例如传递给非托管代码的对象（或者使用了fixed关键字），GC在指针修复时无法修改非托管代码中的引用指针，因此将这些对象移动将发生异常。pinned objects会导致堆出现碎片，但大部分情况来说传给非托管代码的对象应当在GC时能够被回收掉。 （2）分代算法程序可能使用几百M、几G的内存，对这样的内存区域进行GC操作成本很高，分代算法是基于一定的统计学基础，对GC的性能进行了改善。通过对象的生命周期讲对象分成了新对象和老对象也就是分了代，分代算法的假设前提 1.新创建的对象生命周期都比较短，而较老的对象生命周期会更长 2.对部分内存进行回收比基于全部内存的回收操作要快 3.新创建的对象之间关联程度通常较强。堆分配的对象是连续的，关联度较强有利于提高CPU cache的命中率 于是我们把堆分为了3代，分别是Gen0、Gen1、Gen2 如果Gen 0 heap内存达到阀值，则触发0代GC，0代GC后Gen 0中幸存的对象进入Gen1。如果Gen 1的内存达到阀值，则进行1代GC，1代GC将Gen 0 heap和Gen 1 heap一起进行回收，幸存的对象进入Gen2。如图： 2代GC将Gen 0 heap、Gen 1 heap和Gen 2 heap一起回收，Gen 0和Gen 1比较小，这两个代龄加起来总是保持在16M左右；Gen2的大小由应用程序确定，可能达到几G，因此0代和1代GC的成本非常低，2代GC称为full GC，通常成本很高。粗略的计算0代和1代GC应当能在几毫秒到几十毫秒之间完成，Gen 2 heap比较大时，full GC可能需要花费几秒时间。大致上来讲.NET应用运行期间，2代、1代和0代GC的频率应当大致为1:10:100。 （3）几个较为重要的垃圾回收相关apiGC.Collect()：这个的立足点是整个程序，调用这个程序会强制执行一次垃圾回收。也就是像上文提到的那样。 虚构函数：和C++的定义方法相同，它的立足点是类，一个类对象在被垃圾回收时会执行虚构函数中的内容。 Dispose()和close()：也是基于某个类对象，但是这个类对象是有非托管对象的类，GC不会处理非托管对象的释放，所以需要手动调用，有些类对象的是Dispose，而有些是close，但是实现的功能是一样的。如果你自己需要定义自己的Dispose()函数需要实现 IDisposable接口。 注：使用using语句可以自动调用Dispose()函数。 （4）Finalization Queue和Freachable Queue看到这个标题可能有点懵，但是我们可以提取关键词，queue一眼队列，这两个队列并不用于存储真正的对象，而是存储一组指向对象的指针。当程序中使用了new操作符在Managed Heap上分配空间时，GC会对其进行分析，如果该对象含有Finalize方法则在Finalization Queue中添加一个指向该对象的指针。 在GC被启动以后，经过Mark阶段分辨出哪些是垃圾。再在垃圾中搜索，如果发现垃圾中有被Finalization Queue中的指针所指向的对象，则将这个对象从垃圾中分离出来，并将指向它的指针移动到Freachable Queue中。这个过程被称为是对象的复生（Resurrection），本来死去的对象就这样被救活了。为什么要救活它呢？因为这个对象的Finalize方法还没有被执行，所以不能让它死去。Freachable Queue平时不做什么事，但是一旦里面被添加了指针之后，它就会去触发所指对象的Finalize方法执行，之后将这个指针从队列中剔除，这是对象就可以安静的死去了。"},{"title":"C#知识(7)","date":"2022-12-24T15:29:39.000Z","url":"/2022/12/24/CS%E7%9F%A5%E8%AF%86/CS%E7%9F%A5%E8%AF%86-7/","tags":[["C#","/tags/C/"]],"categories":[["C#知识","/categories/C-%E7%9F%A5%E8%AF%86/"]],"content":"本节主要内容：泛型相关知识 1.泛型泛型要会，但是面试稍微考的较少。 C++有泛型，那我C#自然也有，相对于C++的泛型，C#的泛型显得更为简洁，老规矩，实践出真知，来点泛型实例： 输出： 整个代码理解起来应该不难，其中包含了泛型的基本使用方法， 其中还有一些泛型的优点，但我们先不谈，先看看泛型怎么声明的，包括方法，委托，类，接口等 泛型特点看看我们最初的程序的输出。有个数字实在太突出了，对于值类型Int32没有使用泛型而是使用Object类型来接收数据的ArrayList，不断地添加和取出都会造成装箱和拆箱，而众所周知，装箱和拆箱都十分地花时间，这就是用泛型地一个优点，当不知到之后地编程人员会传入什么类型时，它舍弃了以Object为接收类型，而是让后面地编程人员自己定义。剩下地特点用菜鸟教程地总结来稍微拉一下。 它有助于您最大限度地重用代码、保护类型的安全以及提高性能。 您可以创建泛型集合类。.NET 框架类库在 System.Collections.Generic 命名空间中包含了一些新的泛型集合类。您可以使用这些泛型集合类来替代 System.Collections 中的集合类。 您可以创建自己的泛型接口、泛型类、泛型方法、泛型事件和泛型委托。 您可以对泛型类进行约束以访问特定数据类型的方法。 关于泛型数据类型中使用的类型的信息可在运行时通过使用反射获取。 泛型约束泛型约束地作用是确保泛型类使用的参数是提供特定方法的类型。 稍微举个例子作为演示，具体地可以去微软官方看 微软官网对于泛型约束的定义网址："},{"title":"C#知识(6)","date":"2022-12-24T15:29:37.000Z","url":"/2022/12/24/CS%E7%9F%A5%E8%AF%86/CS%E7%9F%A5%E8%AF%86-6/","tags":[["C#","/tags/C/"]],"categories":[["C#知识","/categories/C-%E7%9F%A5%E8%AF%86/"]],"content":"本节主要内容：反射相关知识 1.反射反射指的是System.Reflection的这个命名空间，官方对这个命名空间的作用介绍是：包含通过检查托管代码中程序集、模块、成员、参数和其他实体的元数据来检索其相关信息的类型。 这些类型还可用于操作加载类型的实例，例如挂钩事件或调用方法。其实这就是反射的基本作用。 用途： 它允许在运行时查看特性（attribute）信息。 它允许审查集合中的各种类型，以及实例化这些类型。 它允许延迟绑定的方法和属性（property）。 它允许在运行时创建新类型，然后使用这些类型执行一些任务。 优缺点优点： 1、反射提高了程序的灵活性和扩展性。 2、降低耦合性，提高自适应能力。 3、它允许程序创建和控制任何类的对象，无需提前硬编码目标类。 缺点： 1、性能问题：使用反射基本上是一种解释操作，用于字段和方法接入时要远慢于直接代码。因此反射机制主要应用在对灵活性和拓展性要求很高的系统框架上，普通程序不建议使用。 2、使用反射会模糊程序内部逻辑；程序员希望在源代码中看到程序的逻辑，反射却绕过了源代码的技术，因而会带来维护的问题，反射代码比相应的直接代码更复杂。 （来自菜鸟教程：） 其实简单理解一下主要核心就是使用Type类（这个类派生自MemberInfo，而Member Info所属命名空间为System.Reflection）的API。 反射的使用要使用Type类的api，那首先就要获取到某个东西的Type类型。这里用一个类来举例。 可以用typeof或用你想获取类型的东西调用它内部的GetType()，我在看文献的时候其实看到过另外一种方法： 但是我测试的时候会报出异常，不知道为什么，所以就不用了，毕竟前两个完全足够了。 Type类的属性 Name数据类型名 FullName 数据类型的完全限定名(包括命名空间名) Namespace 定义数据类型的命名空间名 IsAbstract 指示该类型是否是抽象类型 IsArray 指示该类型是否是数组 IsClass 指示该类型是否是类 IsEnum 指示该类型是否是枚举 IsInterface 指示该类型是否是接口 IsPublic 指示该类型是否是公有的 IsSealed 指示该类型是否是密封类 IsValueType 指示该类型是否是值类型 BaseType 获取父类的类型 Type类的方法 GetConstructor(), GetConstructors()：返回ConstructorInfo类型，用于取得该类的构造函数的信息 GetEvent(), GetEvents()：返回EventInfo类型，用于取得该类的事件的信息 GetField(), GetFields()：返回FieldInfo类型，用于取得该类的字段（成员变量）的信息 GetInterface(), GetInterfaces()：返回InterfaceInfo类型，用于取得该类实现的接口的信息 GetMember(), GetMembers()：返回MemberInfo类型，用于取得该类的所有成员的信息 GetMethod(), GetMethods()：返回MethodInfo类型，用于取得该类的方法的信息 GetProperty(), GetProperties()：返回PropertyInfo类型，用于取得该类的属性的信息 这些api多去试试就能熟练使用，我就不演示了。 BindingFlags在使用GetMethods()可能会遇到一个问题，Methods 中只包含 public 权限的成员方法，而 public 权限的属性器也被当做两个 Method 了。 GetMethods 除了获取了类中的方法，也获取了父类中的方法。那能不能回去private权限的成员方法呢，又能不能不获取父类方法呢？ 当然没问题，这里就要用到BindingFlags。 它的本体是个枚举类型，具体可以去微软官网查一下具体的字段方便使用。 这就是反射需要大致掌握的知识，一定要记住一点，反射对性能开销很大，少用。"},{"title":"C#知识(5)","date":"2022-12-24T15:29:35.000Z","url":"/2022/12/24/CS%E7%9F%A5%E8%AF%86/CS%E7%9F%A5%E8%AF%86-5/","tags":[["C#","/tags/C/"]],"categories":[["C#知识","/categories/C-%E7%9F%A5%E8%AF%86/"]],"content":"本节主要内容：事件相关知识 1.事件上一篇讲了委托，这篇讲事件，事件这玩意我自己又没怎么用过，不过没关系，因为这玩意能干的事委托都能干，事实上他其实就是在委托上面加了一些限制来确保委托不会被滥用，至于它的相关知识，了解用法即可，因为用的确实不多。 事件的声明：声明事件之前一定要声明委托类型，或者用C#自带的委托类型如Action&lt;&gt;之类的。三个类，我们把它分别叫做发布器类（prog），订阅类（A），触发类（progMain），使用方法基本上就是这样了。稍微了解以下编译器如何实现事件。 C#编译器编译时把它转换为一个私有的委托和两个方法，两个方法是为了提供登记对某个事件的方法（用+=的时候）和注销对某个事件的关注的方法（用-=的时候）。因为提供的委托是私有类型的，所以事件相较于委托有个非常大的区别，event 只能在所声明的类的内部调用，但是在别的类中可以进行 += 和 -= 操作。 本来想讲讲反射的但是反射有点多，所以只能留到下章了。"},{"title":"C#知识(4)","date":"2022-12-24T15:29:32.000Z","url":"/2022/12/24/CS%E7%9F%A5%E8%AF%86/CS%E7%9F%A5%E8%AF%86-4/","tags":[["C#","/tags/C/"]],"categories":[["C#知识","/categories/C-%E7%9F%A5%E8%AF%86/"]],"content":"本节主要内容：委托相关知识 1.委托本来我是想先聊聊事件的，但是没有委托的事件是不完整的，所以我们还是先聊一下委托， 如果你和我一样是C++和C#双开的，你一定知道C++里面有一个概念叫做指针，而指针中有一类比较特殊的叫做函数指针，函数指针的作用其实就是让一个函数变成一个变量，让函数变成方法的参数，从而指定方法根据不同情况使用不同函数。 其实C#中委托和函数指针的作用几乎一模一样，，又或者说就是一样的。先来看一下用法吧。 委托的使用非常简单，声明的时候使用一个delegate关键词就行。使用的话可以把实例出来的委托名直接作为函数名使用。也可作为参数传给其他的方法。 接下来我们讨论以下委托的深层次的东西（来源于《clr via C#》） 使用起来简答的东西内部的实现细节就会越复杂，为了让委托好用，编译器和clr为我们干了太多事了（感动）（如果不知到clr是什么的，我回头会写，你可以先当它是C#虚拟机） 当我们用以下语句定义一个委托时 编译器会将这行代码定义成下面这样一个类 BeginInvoke和EndInvoke先不谈，先聊一下构造器和Invoke函数 构造器，其实就是C++的构造函数，我们首先注意到的是它的两个参数，既然构造函数有参数，自然是要用这些函数来初始化类中的成员的，所有的委托都是继承于System.MulticastDelegate这个类，而System.MulticastDelegate这个类又是派生自System.Delegate类，这其中有一些历史原因，这里就不展开说了，反正就是继承下来的成员有三个比较重要的： 所以构造器的两个参数分别是target，methodPtr。 最后一个字段invocationList则是在我们像allshow那样将一堆方法构造成一个委托链时会用到，他就像一个链表分别去装构造这个委托的所有方法或委托。 接下来是Invoke方法，这个方法在委托被定义的时候被定义,通过调用target和methodPtr字段在指定的对象上调用包装好的回调方法。所以通过委托调用方法时，其实就是在调用委托类的Invoke方法，所以你直接在编程的时候就直接写成a.Invoke(s)也可以。 最后就是在System.Delegate类中有个方法可以直接取得invocationList中的值。比如下面这个例子就是其中的一种用法。 "},{"title":"C#知识(3)","date":"2022-12-24T15:27:43.000Z","url":"/2022/12/24/CS%E7%9F%A5%E8%AF%86/CS%E7%9F%A5%E8%AF%86-3/","tags":[["C#","/tags/C/"]],"categories":[["C#知识","/categories/C-%E7%9F%A5%E8%AF%86/"]],"content":"本节主要内容：属性、成员和字段的区别，接口相关知识 1.属性、成员和字段的区别字段一般在类内部使用，所以一般是private属性。 属性一般是供外部访问，所以一般是public属性。 成员则是包括属性，字段，方法，事件等。 2.接口接口与其叫接口不如叫约束，他规定了一个东西是什么，而派生类则定义了怎么做 接口中可以声明属性（是属性，不是成员，也不是字段），方法和事件，接口只负责声明，定义由派生类实现。 接口的实现有两种方式，分别是隐式实现和显式实现 1.隐式实现接口的大部分实现都是靠隐式实现 2.显示实现显式实现是为了解决实现多个接口时有可能出现的重名问题。 为了解决重名的问题，需要使用到向上转型 3.接口其他细节 实现接口的任何类型或结构都必须实现器所有的成员 接口类似于只有抽象成员的抽象基类。 实现接口的任何类或结构都必须实现其所有成员。 接口无法直接进行实例化。 其成员由实现接口的任何类或结构来实现。 接口可以包含事件、索引器、方法和属性。 接口不包含方法的实现。 一个类或结构可以实现多个接口。 一个类可以继承一个基类，还可实现一个或多个接口。 "},{"title":"C#知识(2)","date":"2022-12-24T15:16:39.000Z","url":"/2022/12/24/CS%E7%9F%A5%E8%AF%86/CS%E7%9F%A5%E8%AF%86-2/","tags":[["C#","/tags/C/"]],"categories":[["C#知识","/categories/C-%E7%9F%A5%E8%AF%86/"]],"content":"本节主要内容：Partial关键字，结构体struct 1.partial关键字paritial 可以实现类的逻辑拆分到不同的文件。 上面的代码虽然是在不同的文件中，但是在同一个项目中同时定义了两个相同的名字是一定会报错的。 但是当我门使用partial关键字来限定类后则不会报错 运行输出结果： 2.结构体C#中的结构体的定义和C++别无二致，并且声明的方式也是相同的，都是类似与以下的代码： 但是我查了一些资料，发现这两个语言的结构体其实差距还是蛮大的 1.C++ struct首先是C++的结构体，C++的结构体和类几乎没有任何区别，他包含类有的所有特性，不仅能包含变量，也能继承，实现多态甚至类可以继承于结构体，结构体也能继承于类，说实话，我看到这的时候人都傻了，既然结构体和类这么像，为啥还要结构体，我认为是为了兼容c语言的语法吧。而在C++中结构体与类的主要区别就仅仅体现在两个方面： 1.默认的继承访问权限，结构体默认是public继承，class是private的。 2.成员变量的默认访问权限，结构体默认是public，class是private。 2.C# structC#的结构体也没有C的那么单纯，他也能带有方法字段，同时他还能带有索引、属性、运算符方法和事件，大概有以下特点： 结构可带有方法、字段、索引、属性、运算符方法和事件。 结构可定义构造函数，但不能定义析构函数。但是，您不能为结构定义无参构造函数。无参构造函数(默认)是自动定义的，且不能被改变。 与类不同，结构不能继承其他的结构或类。 结构不能作为其他结构或类的基础结构。 结构可实现一个或多个接口。 结构成员不能指定为 abstract、virtual 或 protected。 当您使用 New 操作符创建一个结构对象时，会调用适当的构造函数来创建结构。与类不同，结构可以不使用 New 操作符即可被实例化。 如果不使用 New 操作符，只有在所有的字段都被初始化之后，字段才被赋值，对象才被使用。 结构体中声明的字段，除非将字段声明为 const 或 static，否则无法赋予初值。 赋值时是深拷贝 在为属性器时，不能局部赋值（比如 transofrm.position.x 不能直接赋值） 结构体相比类，内存的回收效率更高，不容易产生 gc，所以需要频繁创建的数据对象建议用结构体来实现，比如 Unity 的 Vector3/2 等。 还有一点需要提醒，C#结构体的默认访问权限是private 其次结构体作为值类型在栈上分配内存存储，至于如果在结构体内有引用类型，那栈中就保存这个引用类型分配在堆的地址，值类型在用完由clr回收机制自动回收，对于结构体中的引用类型，回收的时候只回收用于存储地址的内存，而用于存储引用类型成员变量值的内存，则等待回收机制进行回收。"},{"title":"C#知识(1)","date":"2022-12-24T12:52:38.000Z","url":"/2022/12/24/CS%E7%9F%A5%E8%AF%86/CS%E7%9F%A5%E8%AF%86-1/","tags":[["C#","/tags/C/"]],"categories":[["C#知识","/categories/C-%E7%9F%A5%E8%AF%86/"]],"content":"本节主要内容：引用类型与值类型，程序集和类的访问权限，internal。 1.引用类型、值类型C#中有两种类型：分别是引用类型和值类型 在C#中值类型的变量直接存储数据，而引用类型的变量持有的是数据的引用，数据存储在数据堆中。 图上忘写了，数组也是引用类型 这里顺便提一下C++和C#在内存管理上的区别，C#是一种托管语言，它的垃圾回收机制时由.net平台负责，但是我们还是有必要了解这方面的。 先是C#，程序运行时可能会有多个线程，每个线程在创建时都会生成一个线程栈，值类型的值会直接在线程栈上进行存储，而引用类型的值则会先在堆上开辟一块空间，在栈上存储这块控件的地址 然后是C++,C++编译程序占用内存分为以下几个部分， 1.栈区（stack）：— 由编译器自动分配释放 ，存放函数参数值，局部变量值等。其操作方式类似于数据结构中栈。 2.堆区（heap）：一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收 。注意它与数据结构中堆是两回事，分配方式类似于链表。 3.全局区（静态区）：全局变量和静态变量存储是放在一块，初始化全局变量和静态变量在一块区域， 未初始化全局变量和未初始化静态变量在相邻另一块区域。 程序结束后由系统释放。 4.文字常量区 —常量字符串就是放在这里。 程序结束后由系统释放 5.程序代码区—存放函数体二进制代码。 栈上的内存自动分配了，暂且不聊，这个堆区则是由程序员来分配释放的，C的话是使用malloc分配，free释放，C++则是用new和delete。 重要：值类型在内存管理方面具有更好的效率，并且不支持多态，适合用做存储数据的载体；引用类型支持多态，适合用于定义应用程序的行为。 值得注意的是，引用类型和值类型都继承自System.Object类。不同的是，几乎所有的引用类型都直接从System.Object继承，而值类型则继承其子类，即直接继承System.ValueType。即System.ValueType本身是一个类类型，而不是值类型。其关键在于ValueType重写了Equals()方法，从而对值类型按照实例的值来比较，而不是引用地址来比较。 2.程序集和类的访问权限internal程序集是一个或多个类型的一文件及资源文件的集合（感觉和文件夹差不多）。 Microsoft引入这个概念的目的是可以将代码分成多个文件，如果客户端永远使用不到这多程序可以永远不将这段程序加载到客户端上。 然后internal这个类访问权限以前我也完全没听说过，也是最近在看《clr via C#》这本书才了解到这个访问权限，它所修饰的类只能在同一个程序集中被访问，而同一个程序集表示同一个dll程序集或同一个exe程序集。 有人可能会注意到dll这个词，当时我读到这也挺疑惑的，因为我之前曾经读过《深入理解计算机系统》，这书提到过动态链接库这样一个概念，而动态链接库在windows中的后缀也是dll。 接下来演示以下unity中如何使用程序集 首先先说明一下使用程序集在unity的优点吧。 1.提高编译速度：unity将用户定义的C#文件默认放进Assembly-Csharp.dll程序集中，每当编写或修改完代码时，unity需要编译整个程序集的代码，来判断是否编译错误。使用多个程序集就能解决这个问题。 2.减少项目的耦合度：不用多解释，和设计模式思路一样，而且可以快速判断代码出在哪一个程序集中的文件。通过程序集的依赖，来联系各个程序集。 方法： 1.在一个空的文件夹中右键，选择Create，选择Assembly Definition，在再这个文件夹中创建的文件将自动划入创建的程序集中 2.在程序集的inspector面板上的Assembly Definition References添加需要依赖的类，则可以完成程序集的依赖设置。 "},{"title":"Unity网络游戏开发(3)","date":"2022-11-16T07:38:12.000Z","url":"/2022/11/16/Unity%E7%BD%91%E7%BB%9C%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/Unity%E7%BD%91%E7%BB%9C%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91-3/","tags":[["网络游戏","/tags/%E7%BD%91%E7%BB%9C%E6%B8%B8%E6%88%8F/"],["unity","/tags/unity/"]],"categories":[["Unity网络游戏开发","/categories/Unity%E7%BD%91%E7%BB%9C%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"]],"content":"Unity网络游戏开发第三部分 第五章 深入了解TCP5.1 TCP的连接、传输和终止我们都听说过三次握手，四次挥手的表述，但是很难理解为什么要三次握手四次挥手。 要理解这点，我们首先要理解到TCP是一种面向连接的，可靠的，基于字节流的传输层协议，像连接这种事为了确保可靠一定要保证双方的网络是相通的。 先来看三次握手： 主角： 主机一和主机二 过程：主机一向主机二发送请求连接的报文，由于网络环境差，致使此报文一直呆在网络环境中，最终导致失效，主机一或许早已完成连接，或许放弃了连接，反正此时不打算和主机二连接了，此时这个报文到达了主机二，主机二以为是主机一发的，假设只是两次握手，主机二向主机一发出确认报文问，但是主机一并没有打算连接，所以丢弃，但是主机二还以为连上了苦苦的在那里等，这就导致了资源的浪费。所以需要三次握手。 本人理解:一个面向连接的协议自然要保证连接的双向连通，两次握手，主机一知道了主机一到主机二的道路和主机二到主机一的道路都是通的，但是主机二只知道主机一到主机二的道路是通的，不知道主机二到主机一的道路是通的。除非主机一发送确认报文，并且主机二清楚的收到。（有点绕，可以多看几遍） 再来看看四次挥手： 主机一向主机二请求断开连接，代表着主机一并没有数据往主机二发了，但是不代表主机二没有数据往主机一发了，所以主机一你先别急，等主机二发完了，向主机一再发送请求断开连接，主机一再处理完主机二发来的剩余信息后才发送确认信息，然后主机一释放连接，主机二也释放连接。 5.2 常用的TCP参数Socket相当于TCP与UDP提供的接口，所以我们可以通过Socket获取或修改TCP的很多参数 ，这有利于我们构造更为实用的框架。 5.3 Close的恰当的时机在TCP参数中的LingerState能够尽量发完操作系统缓冲区的信息，但是不要忘了我们之前写的发送方法，我们在发送前会将消息放入自己设置的缓冲区，这些数据在关闭的时候就会丢失。 解决方法是设置一个bool值判断是否正在Closing，主动关闭的一方如果还有要发送的消息就将isClosing设置为true，关闭前就判断isClosing为true就不能关闭，如果为false就能发送。 5.4 心跳机制如果玩游戏一半，网线被噶了，那就没机会发送FIN信号了，如果不处理的话，服务端就一直占着系统资源，TCP有一个检测机制，如果在指定的时间没有数据传送就会发送一个信号，对端如果收到信号就会返回确认信号，如果一段时间没有收到回应就会重试几次，如果都没有，会认为网络不通关闭Socket。 启用方法： 但是TCP提供的方法不太适用于游戏，因为网游强调一个高实时性。 所以一般会自己实现心跳机制，客户端会定时向服务端发出PING消息，服务端收到回应PONG消息，若是很久没收到就说明连接不通，释放资源。 第六章 帧同步和状态同步6.1 状态同步状态同步指的是同步状态信息，比如角色需要做出的动作，角色的位置坐标、旋转发送给服务端，服务端再做广播。这种同步方式会将核心的逻辑判断交给服务端，否则就会导致延迟过高。举个例子： 如果服务端只是作为一个转发器，那么当一个玩家同步自己释放技能的状态，很有可能网络原因导致其他主机很晚才收到，这就会导致延迟很高，而如果只是将释放技能这个状态同步给服务端，服务端收到后进行一定程度的判断和运算再将处理后的状态同步给所有的玩家，这样再一定程度上保持了所有玩家是同步的，但是这也会导致响应慢等问题。所以状态同步一般不会适用于实时度比较高的pvp游戏。 6.1.1 跟随算法上述是服务端处理完再广播的方式，还有一种方法就是服务端还是当个转发工具人，网络不好的情况下势必会导致经常瞬移，所以聪明的程序大佬们想到了一个方法，就是如果获得了一个状态与客户端的状态有差距就以一定的速度将物体达到这个状态，只要同步频率够高误差就可以忽略，但是如果我们仔细分析一下，这个相对于直接状态同步误差更大，于是人们又引用了预测算法。 6.1.2 预测算法在某些有规律可循的条件下比如坦克的匀速运动，或者匀加速运动，我们可以预测坦克接下来的位置，我们就让坦克提前走到预测的位置去，但是这也会引发一个问题，就是玩家控制的东西一般来说没啥规律，所以如果玩家再运行途中停了下来，就会看到一个神奇的现象，一个往前开的坦克又默默的退了回来，而且预测算法也比较复杂。 两种算法各有优势，具体情况具体分析。 6.2 帧同步在游戏中同步的是玩家的操作指令，操作指令包含当前的帧索引。一般的流程是客户端上传操作到服务器， 服务器收到后并不计算游戏行为， 而是转发到所有客户端。帧同步其实是指令同步的一种。 6.2.1 指令同步玩家只同步指令信息，相同的输入 + 相同的时机 = 相同的输出。 6.2.2 同步帧帧同步的帧与unity中的帧是两个概念，在unity中我们说Update函数每一帧调用一次，我们也说Update调用的快慢取决于使用的设备，那如果某个设备Update慢点就没法保证相同的时机了，这些偏差会导致整个游戏不同的客户端差距巨大，所以我们会另外引入一个叫同步帧的概念。帧同步的特性导致客户端的逻辑实现和表现实现必须完全分离。Unity中的一些方法接口(如 Invoke， Update、动画系统等)是不可靠的，所有要自己实现一套物理引擎、数学库，做到逻辑和表现分离。 这样即使Unity的渲染是不同步的，但是逻辑跑出来是同步的。 6.3 帧同步与状态同步对比"},{"title":"Unity网络游戏开发(2)","date":"2022-11-16T07:23:53.000Z","url":"/2022/11/16/Unity%E7%BD%91%E7%BB%9C%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/Unity%E7%BD%91%E7%BB%9C%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91-2/","tags":[["网络游戏","/tags/%E7%BD%91%E7%BB%9C%E6%B8%B8%E6%88%8F/"],["unity","/tags/unity/"]],"categories":[["Unity网络游戏开发","/categories/Unity%E7%BD%91%E7%BB%9C%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"]],"content":"Unity网络游戏开发第二部分 第四章 正确收发数据流第四章和第五章会涉及到一些TCP的一些机制 4.1 TCP数据流我们都听说过一句话TCP是一种流模式协议，UDP是一种数据报模式的协议。 TCP的流模式指的就是发送的数据如同水流一样发送方将数据发送出去时操作系统会将数据放在发送缓存中，然后接收方在接收前也会先将数据放入接收缓存中，而读取的速度取决于设备和操作系统，这也就意味着发送的次数与接收的次数并不一定相同。你发送的数据量不能大于对方的接收缓存（流量控制），如果你硬是要发送过量数据，则对方的缓存满了就会把多出的数据丢弃。 UDP和TCP不同，发送端调用了几次write，接收端必须用相同次数的read读完。UDP是基于报文的，在接收的时候，每次最多只能读取一个报文，报文和报文是不会合并的，如果缓冲区小于报文长度，则多出的部分会被丢弃。 4.2 粘包与半包基于TCP的流模式就会导致一个比较关键的问题，如果客户端在极短的时间内发送多个数据，就会导致接收的时候将两段代码合并在一起导致解析错误之类的问题。 我们看一下大乱斗游戏的一段代码。 这里我用了一个协程让程序等0.1秒之后再请求服务器上其他玩家的数据，为什么呢？我们把他改成连续发送会怎样呢？ 我们先看看协程方式下服务端收到的消息 再将程序改成连续发送 可以看到服务端将连续两次发的消息合成了一句消息，导致了服务端程序无法解析，导致程序报错并退出，如果正在运营的网游出现这种情况导致服务器停机，这样会造成很大的损失。 这个现象被称为粘包现象，那么半包现象也好理解了，运气较差的话操作系统将一半的指令读取了，这样也会给服务端造成比较那一处理的麻烦。 一般有三种方法可以解决粘包与半包问题： 4.2.1 长度信息法这个方法是在每个数据包前加上长度信息，比如传输hello就变成5hello，一个字节最多表示255个字节，稍微有点少，所以一般会选择Int16或者Int32来表示数据长度，这样再服务端处理的时候就可以先放进一个缓冲区，通过程序保证每一次都能拿到对应的发送信息。 4.2.2 固定长度法规定每条信息的长度，如果一条信息短于这个规定长度则用规定的字符将信息填充到这个固定长度，比如规定长度为10，我要发送hello，规定用.来补全，就变成了hello…..了。 4.2.3 结束符号法规定某个不会使用的符号作为结束符号，这样只需要检测到这个符号，就把这个符号之前的信息切出来，保证服务端接收的次数和客户端发送的次数一致。 书上采用的是长度信息法。 4.3 大端小端问题使用长度信息法的话我们需要将代表长度的Int16或者Int32转化成byte数组发送出去，到了接收方肯定需要再转化成Int类型这个时候会用到一下两个方法： 而这两句可能会导致大端小端问题 4.3.1 什么是大端小端学过计组的可能有了解，不同的CPU使用了不同的存储方式，这是由于一些历史的因素导致的。 大端：高地址存低字节，低地址存高字节 小端：低地址存低字节，高地址存高字节 例如： 这是一个16位的内存，我们将他转化位一个Int16类型的数 如果是个大端的系统那么高地址存低字节，高地址的00000010会转化为2，低地址的存高字节，低地址的00000001会转化成256，整个数据会转化为256+2=258。 如果是个小端的系统那么高地址存高字节，高地址的00000010会转化为512，低地址存低字节，低地址的00000001会转化成1，整个数据会转化成512+1=513。 所以同样的一串二进制数在不同的系统中会解析成不同的数字，非常的不方便。 4.3.2 如何解决大端小端的问题既然计算机本身不能解决问题，那么我们就用程序来解决问题，我们首先规定数据的传输必须使用小端输入，因为我们必须使用小端编码，所以我们需要判断系统是否是小端，如果不是小端，那么我们就使用Reverse函数来转化成小端模式。 一下是发送数据的大致代码 拓展: 虽然BitConverter.IsLittleEndian可以直接调用并判断计算机的大小端，但是我们也应该学习一下如何去实现判断大小端的方法，我分别用C#，C++，C三种语言实现一下： C++： C++使用了union的特点来测试：不懂union可以去查一下 C： C++完全兼容C，所以也可以用这种方法 拓展结束 发送端的代码搞定了，但是如果接收端是大端的话BitConverter.ToInt16也会出问题，所以我们要自己解析接收到的代码： 这段代码理解起来可能稍微有点难理解，首先我们先将第二个字节向左移动八位，也就是乘了一个256然后与第一个字节相与，这在二进制中代表的是相加。最后再强转成Int16类型的数值。 4.4 不完整发送之前介绍到TCP在发送时会先将需要发送的数据先放入操作系统的缓冲区，如果操作系统缓冲区设计的比较小，在网络环境较差的环境下，导致操作系统的缓冲区满了，这个时候再发送，溢出的部分会被抛弃掉引发不完整发送，虽然再网络通畅的环境下，Send只发送部分数据的改率不高，很多商业游戏都没有处理这种情况，但是我们要知道这种情况如何去处理。 4.4.1 解决方案要让数据能够完整发送，最好的方法就是将这个数据在发送前保存起来，如果发生不完整发送，在回调函数中继续发送数据。 代码实现： 解析以上这段代码，首先我们定义了自己的缓冲区，缓冲区偏移量，缓冲区的剩余长度。然后分别赋值，调用BeginSend，发送完成调用回调函数，将偏移量加上已发送数据，定位到发送到哪了，将剩下的长度减去发送的长度，用于判断是否发完，没发完继续调用BeginSend继续发送。 这种方法已经解决了大部分的问题，但是如果我们在还没来的及调用回调函数发出剩下的数据时又再次调用了Send，那么sendBytes，length，readIdx都会被重置，该发不完还是发不完（你这不是什么都没解决嘛），为此我们有必要牺牲一点点内存来构造一个加强版的缓冲区。我们将设计一个缓冲队列，每一次发送新的消息都将新消息写入队列的末尾，等前面的消息读取完，就将前面的消息弹出队列，开始读取后面的消息。 补充：如果你有过开发动作游戏的经验的话，你就会发现很多设计都有一曲同工之妙，比如你处理玩家的一系列指令的话，也可以将这些指令先放入一个队列，程序再一个一个调用。而且如果有什么特殊攻击的话也可以通过此判断。 我们来看看实现的代码： 队列我们直接使用Queue 看一下如何使用呢： ​ 这样的程序看似已经非常完善了，但是我们依旧忽略了一个问题，这是个异步方法，回调函数和BeginSend运行于不同的线程，不同的线程操作同一段内存一定要注意一个问题，那就是线程冲突，设想一种情况：我们先发一条消息，这个消息放进了队列，此时开始运行Send，这个时候Send函数又被调用，将另一条消息放入队列这个时候回调函数刚还执行完并将第一条消息发送出去，再次调用了BeginSend，将第二条消息发送出去了，原线程也在此时调用了BeginSend，于是一条消息发送了两次。 画个图理解以下 学过操作系统的都明白这中情况怎么处理，简单来说就是加锁： 4.5 高效接收数据既然要追求极致那就贯彻到底，接收数据我们也可以使用之前定义的ByteArray 首先我们要解决两个问题 1.能读写信息 2.缓冲区不够长时自动扩张缓冲区 那么我们就来完善以下ByteArray代码： 使用方法： 这里就不多做介绍了，具体的内容和实现可以多看看代码"},{"title":"Unity网络游戏开发(1)","date":"2022-11-16T06:19:47.000Z","url":"/2022/11/16/Unity%E7%BD%91%E7%BB%9C%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/Unity%E7%BD%91%E7%BB%9C%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91-1/","tags":[["网络游戏","/tags/%E7%BD%91%E7%BB%9C%E6%B8%B8%E6%88%8F/"],["unity","/tags/unity/"]],"categories":[["Unity网络游戏开发","/categories/Unity%E7%BD%91%E7%BB%9C%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"]],"content":"近几年大量的网络游戏大热，相较于单机多了更多的趣味，且手游越来越火热，所以网络游戏开发势必成为一个客户端程序员的基本素养，不仅要了解客户端的搭建，还要熟悉服务端的基本实现方式。 本系列专栏作为Unity3D网络游戏实战的笔记总结 第一章 网络游戏的开端1.1 服务端一款网络游戏分为客户端服务端两个部分，客户端在用户设备上运行，服务端则在游戏运营商的服务器上运行。服务端与客户端之间通常使用TCP网络通信，各个服务端之间互相使用TCP连接，形成服务端集群。 1.2 Socket我们都知道计算机网络七层模型和五层模型，那在学习的时候常用的五层模型来说，分为物理层，数据链路层，网络层，传输层，应用层，我们也知道传输层实现端到端的通信主要的两个协议：TCP协议、UDP协议，这两个协议的区别与实现请自行去学习计算机网络这门课，我们今天要介绍的是Socket。可能有人和我当时有一样的疑问，这个Socket是应用层的还是传输层的，经过我的查阅，这个Socket应该和TCP、UDP一样属于传输层，我们可以把它理解为TCP、UDP协议的封装，以及对外提供的接口。 那么它其中都包含了什么呢？ ​ 1.协议（TCP，UDP） ​ 2.本地IP地址 ​ 3.本地端口 ​ 4.远程IP地址 ​ 5.远程端口 每一条Socket连接代表着：本地Socket→本地端口→网络介质→远程端口→远程Socket 的链路。 为了方便之后的使用，我们先了解一下Socket通信的完整流程（TCP协议） ​ 1.创建一个Socket对象（使用API Socket），绑定本地使用的端口，服务端一定要在程序中指定端口进行绑定（使用API Bind），而客户端在连接（使用API Connect）时会由系统分配端口，可以省去绑定步骤 ​ 2.服务端开启监听（使用API Listen），等待客户端接入 ​ 3.客户端连接服务器（使用API Connect） ​ 4.服务端接收连接（使用API Accept） ​ 5.客户端与服务端通过Send和Receive等API收发数据 ​ 6.某一方关闭连接（使用API Close），结束通信 第二章 异步API2.1 API如果使用上述API会因为是同步程序导致在网络环境稍差的情况下会造成客户端卡顿，所以同步API一般只用于早期测试，真正开发的时候会尽量使用异步API，虽然异步API不是那么容易理解，但是他能使客户端更加流畅。 而这些API基本都是上面描述的API前面加上Begin前缀，比如Connect的异步调用就是BeginConnect。 所有的异步API参数中都有一个委托，这个委托需要放入一个回调函数，以达到异步的效果。 2.2 非异步方式解决程序卡顿问题异步很好，而且在实际的游戏开发中也会更多的使用异步API来实现网络编程。 但是同时也有其他的一些API也能够达到类似的目的。也就是Poll、Select的API。 2.2.1 PollPoll的作用就是判断某个Socket是否可读可写可用，调用方式为 microSeconds：等待回应的时间，-1为一直等待，0表示不阻塞 mode： SelectMode.SelectRead：是否可读 SelectMode.SelectWrite：是否可写 SelectMode.SelectError：是否可用 Poll的服务端的核心代码为： Poll简单来说就是一个一个检测是否有可读信息，有就处理，这样就能避免明明没有可用的消息还是将程序阻塞在哪里，导致卡顿，但是由于没有数据的时候也还是需要检测数据，同样也还是浪费，且导致CPU占用率过高。 2.2.2 SelectSelect相对Poll来说实现了多路复用，即同时检测多个Socket状态，调用方式为： 前三个参数分别对应三个列表，第四个参数为等待回应时间 Select服务端的核心代码： Select与Poll其实很相近，只是Poll是一个一个处理，导致其频繁的调用造成CPU占用率高，但是Select集中去处理，调用次数少CPU占用率就会稍微低一点，但是两个方法都是使用一个死循环循环的去执行，在客户端中也是在Update函数里面不停检测，所以商业上为了达到性能的极致通常还是会选用异步。 第三章 大乱斗游戏本游戏的原代码 服务端 客户端"}]